{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing manual compression of image captions on stale (offline) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dahuffman in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (0.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dahuffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from wandb) (8.1.3)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Using cached GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from wandb) (5.9.8)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.40.3-py2.py3-none-any.whl (257 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.8/257.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp39-cp39-macosx_10_9_x86_64.whl (11 kB)\n",
      "Requirement already satisfied: setuptools in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from wandb) (68.0.0)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from wandb) (4.9.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.41 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.40.3 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikilravi10\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "from transformers import AdamW\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import logging\n",
    "from dahuffman import HuffmanCodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and its components\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import list_datasets\n",
    "len(list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 40670/40670 [00:00<00:00, 222482.65it/s]\n",
      "Using custom data configuration test2017-bcc41c24fb40aad9\n",
      "Found cached dataset imagefolder (/Users/nikilravi/.cache/huggingface/datasets/imagefolder/test2017-bcc41c24fb40aad9/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset (for example, a subset of the COCO dataset)\n",
    "# TODO: Potential datasets with repititive nature that can be used: MS COCO, Flickr30k, Visual Genome, SBU Captions \n",
    "\n",
    "# load small part of the coco dataset from all the .jpg images in datasets/mscoco/test2015\n",
    "dataset = load_dataset(\"datasets/coco/images/test2017/\", split=\"train[:25]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(image, max_length=128):\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    output_ids = model.generate(inputs[\"pixel_values\"], max_length=max_length)\n",
    "    caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dataset and generate captions\n",
    "max_length = 128\n",
    "generated_captions = []\n",
    "\n",
    "for data in dataset:\n",
    "    image = data['image']\n",
    "    caption = generate_caption(image, max_length=max_length)\n",
    "    generated_captions.append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_encoding_dict(captions, encoding_dict):\n",
    "    for caption in captions:\n",
    "        words = caption.split()\n",
    "        encoding_dict.update(words) # purpose of update is to add the words to the dictionary if they don't exist\n",
    "    return encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dict = Counter() # Counter is a subclass of dictionary for counting hashable objects\n",
    "threshold = 2 # threshold for word frequency # TODO: find a good threshold\n",
    "\n",
    "update_encoding_dict(generated_captions, encoding_dict)\n",
    "\n",
    "# Optionally, create a more compressed form based on frequency\n",
    "compressed_dict = {word: idx for idx, (word, freq) in enumerate(encoding_dict.items()) if freq > threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a green truck parked next to a curb ',\n",
       " 'a baseball player swinging a bat at a ball ',\n",
       " 'a cow is standing in a field of grass ',\n",
       " 'a man is playing tennis on a clay court ',\n",
       " 'a man and a woman playing a game of frisbee ',\n",
       " 'a woman and a man are drinking wine ',\n",
       " 'a zebra standing in a fenced in area ',\n",
       " 'a horse grazing in a field with a tree ',\n",
       " 'a bird perched on top of a bird feeder ',\n",
       " 'a train on a track near a fence ',\n",
       " 'an elephant with a large trunk standing on a dirt ground ',\n",
       " 'a stuffed animal with a teddy bear on it ',\n",
       " 'a plate of food with meat, broccoli and potatoes ',\n",
       " 'a man in a suit and tie looking at his cell phone ',\n",
       " 'a motorcycle parked on the side of a road ',\n",
       " 'a bear walking through a forest with leaves ',\n",
       " 'a plate of food on a table ',\n",
       " 'a remote control sitting on top of a couch ',\n",
       " 'a large jetliner flying through a cloudy sky ',\n",
       " 'a man in a suit and tie speaking to a crowd ',\n",
       " 'a plate of food with meat, rice and vegetables ',\n",
       " 'a person jumping a skateboard on a ledge ',\n",
       " \"a giraffe standing next to a tree with a leaf on it's head \",\n",
       " 'a man riding a wave on top of a surfboard ',\n",
       " 'a bedroom with a bed, chair, and a window ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 57,\n",
       "         'on': 11,\n",
       "         'of': 9,\n",
       "         'with': 8,\n",
       "         'and': 7,\n",
       "         'in': 6,\n",
       "         'man': 6,\n",
       "         'standing': 4,\n",
       "         'to': 3,\n",
       "         'top': 3,\n",
       "         'plate': 3,\n",
       "         'food': 3,\n",
       "         'parked': 2,\n",
       "         'next': 2,\n",
       "         'at': 2,\n",
       "         'is': 2,\n",
       "         'field': 2,\n",
       "         'playing': 2,\n",
       "         'woman': 2,\n",
       "         'tree': 2,\n",
       "         'bird': 2,\n",
       "         'large': 2,\n",
       "         'bear': 2,\n",
       "         'meat,': 2,\n",
       "         'suit': 2,\n",
       "         'tie': 2,\n",
       "         'through': 2,\n",
       "         'green': 1,\n",
       "         'truck': 1,\n",
       "         'curb': 1,\n",
       "         'baseball': 1,\n",
       "         'player': 1,\n",
       "         'swinging': 1,\n",
       "         'bat': 1,\n",
       "         'ball': 1,\n",
       "         'cow': 1,\n",
       "         'grass': 1,\n",
       "         'tennis': 1,\n",
       "         'clay': 1,\n",
       "         'court': 1,\n",
       "         'game': 1,\n",
       "         'frisbee': 1,\n",
       "         'are': 1,\n",
       "         'drinking': 1,\n",
       "         'wine': 1,\n",
       "         'zebra': 1,\n",
       "         'fenced': 1,\n",
       "         'area': 1,\n",
       "         'horse': 1,\n",
       "         'grazing': 1,\n",
       "         'perched': 1,\n",
       "         'feeder': 1,\n",
       "         'train': 1,\n",
       "         'track': 1,\n",
       "         'near': 1,\n",
       "         'fence': 1,\n",
       "         'an': 1,\n",
       "         'elephant': 1,\n",
       "         'trunk': 1,\n",
       "         'dirt': 1,\n",
       "         'ground': 1,\n",
       "         'stuffed': 1,\n",
       "         'animal': 1,\n",
       "         'teddy': 1,\n",
       "         'it': 1,\n",
       "         'broccoli': 1,\n",
       "         'potatoes': 1,\n",
       "         'looking': 1,\n",
       "         'his': 1,\n",
       "         'cell': 1,\n",
       "         'phone': 1,\n",
       "         'motorcycle': 1,\n",
       "         'the': 1,\n",
       "         'side': 1,\n",
       "         'road': 1,\n",
       "         'walking': 1,\n",
       "         'forest': 1,\n",
       "         'leaves': 1,\n",
       "         'table': 1,\n",
       "         'remote': 1,\n",
       "         'control': 1,\n",
       "         'sitting': 1,\n",
       "         'couch': 1,\n",
       "         'jetliner': 1,\n",
       "         'flying': 1,\n",
       "         'cloudy': 1,\n",
       "         'sky': 1,\n",
       "         'speaking': 1,\n",
       "         'crowd': 1,\n",
       "         'rice': 1,\n",
       "         'vegetables': 1,\n",
       "         'person': 1,\n",
       "         'jumping': 1,\n",
       "         'skateboard': 1,\n",
       "         'ledge': 1,\n",
       "         'giraffe': 1,\n",
       "         'leaf': 1,\n",
       "         \"it's\": 1,\n",
       "         'head': 1,\n",
       "         'riding': 1,\n",
       "         'wave': 1,\n",
       "         'surfboard': 1,\n",
       "         'bedroom': 1,\n",
       "         'bed,': 1,\n",
       "         'chair,': 1,\n",
       "         'window': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionAutoencoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, max_seq_length):\n",
    "        super(CaptionAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_embedding = nn.Embedding(vocab_size, embedding_dim) # input shape has to be (batch_size, sequence_length), output shape is (batch_size, sequence_length, embedding_dim)\n",
    "        self.encoder_rnn = nn.GRU(embedding_dim, hidden_dim, num_layers=4, batch_first=True) # output shape is (batch_size, sequence_length, hidden_dim)\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_rnn = nn.GRU(hidden_dim, hidden_dim, num_layers=4, batch_first=True) # output shape is (batch_size, sequence_length, hidden_dim)\n",
    "        self.decoder_output = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def encode(self, captions):\n",
    "        embedded = self.encoder_embedding(captions)\n",
    "        encoded, _ = self.encoder_rnn(embedded)\n",
    "        return encoded[:, -1, :]\n",
    "\n",
    "    def decode(self, encoded):\n",
    "        # Repeat the encoded state across the sequence length\n",
    "        repeated_encoded = encoded.unsqueeze(1).repeat(1, self.max_seq_length, 1) \n",
    "        decoded, _ = self.decoder_rnn(repeated_encoded)\n",
    "        output = self.decoder_output(decoded)\n",
    "        return output\n",
    "\n",
    "    def forward(self, captions):\n",
    "        encoded = self.encode(captions)\n",
    "        decoded = self.decode(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, captions):\n",
    "        self.encodings = encodings\n",
    "        self.captions = captions\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.captions[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `dataset` is your dataset containing images and captions\n",
    "images = [data['image'] for data in dataset]\n",
    "captions = generated_captions\n",
    "\n",
    "# Process images and captions\n",
    "inputs = feature_extractor(images=images, return_tensors=\"pt\")\n",
    "outputs = tokenizer(captions, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Assuming 'captions' is a tensor of tokenized captions generated by VLM\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = 50257\n",
    "hidden_dim = 512\n",
    "max_seq_length = 128\n",
    "autoencoder = CaptionAutoencoder(vocab_size, embedding_dim, hidden_dim, max_seq_length)\n",
    "autoencoder_output = autoencoder(outputs[\"input_ids\"])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = CaptionDataset(inputs, outputs[\"input_ids\"])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, original_weight, rank):\n",
    "        super(LoRALayer, self).__init__()\n",
    "        self.original_weight = original_weight\n",
    "        self.rank = rank\n",
    "        self.U = nn.Parameter(torch.Tensor(self.original_weight.size(0), self.rank))\n",
    "        self.V = nn.Parameter(torch.Tensor(self.rank, self.original_weight.size(1)))\n",
    "        nn.init.xavier_uniform_(self.U)\n",
    "        nn.init.xavier_uniform_(self.V)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.original_weight + self.U @ self.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the first attention layer of the encoder\n",
    "# TODO: Try modifying other layers as well and check the results\n",
    "lora_layers = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    original_weight = model.encoder.encoder.layer[0].attention.output.dense.weight\n",
    "    lora_layer = LoRALayer(original_weight, rank=10).forward()  # Choose an appropriate rank\n",
    "    # assign the new layer to the model\n",
    "    model.encoder.encoder.layer[0].attention.output.dense.weight.copy_(lora_layer)\n",
    "    # add the layer of the model to the list of LoRA layers\n",
    "    lora_layers.append(model.encoder.encoder.layer[0].attention.output.dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_lora_param(param, lora_layer):\n",
    "    # check if the parameter is part of the LoRA layer\n",
    "    print (lora_layer.parameters())\n",
    "    print (\"nuj\")\n",
    "    print (param)\n",
    "    return param in lora_layer.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(outputs, batch, lora_layers, autoencoder, standard_lambda_val = 1, lora_lambda_val = 0.01, compression_lambda_val = 0.01):\n",
    "    # Standard captioning loss\n",
    "    standard_loss = outputs.loss\n",
    "\n",
    "    # Autoencoder compression reward\n",
    "    captions = batch['labels']\n",
    "    compressed_captions = autoencoder.encode(captions)\n",
    "    # Measure the sparsity of the compressed representation (e.g., using L1 norm) # TODO: Try other measures\n",
    "    compression_reward = torch.norm(compressed_captions, p=1)\n",
    "    # Adjust the reward: lower norm (more sparse) should lead to lower loss (higher reward)\n",
    "    compression_loss = compression_reward\n",
    "\n",
    "    # Optionally, add a term for LoRA regularization if needed\n",
    "    lora_regularization = 0\n",
    "    # for param in model.parameters():\n",
    "    #     for lora_layer in lora_layers:\n",
    "    #         if is_lora_param(param, lora_layer):\n",
    "    #             lora_regularization += torch.norm(param)\n",
    "    return standard_lambda_val* standard_loss + compression_lambda_val * compression_loss + lora_lambda_val * lora_regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_criterion1 = nn.CrossEntropyLoss()\n",
    "\n",
    "def ae_criterion2 (reconstructed_caption, original_caption, end_of_text_token_id):\n",
    "\n",
    "    loss= 0\n",
    "\n",
    "    for i in range(len(original_caption)):\n",
    "\n",
    "        # remove all end of text tokens from the right in original caption\n",
    "        trim_index = 0\n",
    "        for j in range(len(original_caption[i])-1, -1, -1):\n",
    "            if original_caption[i][j] != end_of_text_token_id:\n",
    "                trim_index = j\n",
    "                break\n",
    "        trim_index += 1\n",
    "\n",
    "        # Trim the trailing spaces\n",
    "        trimmed_original = original_caption[i][:trim_index]\n",
    "        trimmed_reconstructed = reconstructed_caption[i][:trim_index]\n",
    "\n",
    "        # Calculate the loss (assuming cross-entropy loss)\n",
    "        loss += ae_criterion1(trimmed_reconstructed, trimmed_original)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nikilravi/projects/VLMCaptionCompressor/wandb/run-20240211_204849-h82m55r4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nikilravi10/vlm-compression/runs/h82m55r4' target=\"_blank\">twinkling-rabbit-1</a></strong> to <a href='https://wandb.ai/nikilravi10/vlm-compression' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nikilravi10/vlm-compression' target=\"_blank\">https://wandb.ai/nikilravi10/vlm-compression</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nikilravi10/vlm-compression/runs/h82m55r4' target=\"_blank\">https://wandb.ai/nikilravi10/vlm-compression/runs/h82m55r4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"vlm-compression\",\n",
    "    config={\"dataset_size\": \"25\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderModel(\n",
       "  (encoder): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (pooler): ViTPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, vlm_lr, ae_lr, vlm_optimizer, ae_optimizer, device, save_every=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        loop = tqdm(train_loader, leave=True)\n",
    "        for batch in loop:\n",
    "            # Move batch to device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # Fine tune VLM with custom loss\n",
    "            # Forward pass\n",
    "            model.zero_grad()\n",
    "            outputs = model(**batch)\n",
    "            vlm_loss = custom_loss(outputs, batch, lora_layers, autoencoder)\n",
    "            # Backward pass and optimization\n",
    "            vlm_optimizer.zero_grad()\n",
    "            vlm_loss.backward()\n",
    "            vlm_optimizer.step()\n",
    "\n",
    "            # Train the autoencoder\n",
    "            autoencoder.zero_grad()\n",
    "            captions = batch['labels']\n",
    "            compressed_captions = autoencoder.encode(captions)\n",
    "            reconstructed_captions = autoencoder.decode(compressed_captions)\n",
    "            # reconstructed_flat = reconstructed_captions.view(-1, reconstructed_captions.size(-1))\n",
    "            # captions_flat = captions.view(-1)\n",
    "            end_of_text_token_id = tokenizer.encode('<|endoftext|>')[0]\n",
    "            ae_loss = ae_criterion2(reconstructed_captions, captions, end_of_text_token_id)\n",
    "            ae_loss.backward()\n",
    "            ae_optimizer.step()\n",
    "\n",
    "            # TODO: change loss as combination of vlm_loss and ae_loss instead of individual losses\n",
    "\n",
    "            # Update progress bar\n",
    "            loop.set_description(f\"Epoch {epoch}\")\n",
    "            loop.set_postfix(vlm_loss=vlm_loss.item(), ae_loss=ae_loss.item())\n",
    "\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"vlm_loss\": vlm_loss,\n",
    "                    \"ae_loss\": ae_loss,\n",
    "                    \"vlm_lr\": vlm_lr,\n",
    "                    \"ae_lr\": ae_lr\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if epoch % save_every == 0:\n",
    "                # Save the model\n",
    "                # create directory to save the model if it doesn't exist\n",
    "                if not os.path.exists(\"auto_epoch_exp\"):\n",
    "                    os.mkdir(\"auto_epoch_exp\")\n",
    "                # save model checkpoint to models directory using current timestamp and date\n",
    "                torch.save(model.state_dict(), f\"auto_epoch_exp/{time.strftime('%Y%m%d-%H%M%S')}-{epoch}-{vlm_lr}-{ae_lr}-{vlm_loss}-{ae_loss}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikilravi/opt/anaconda3/envs/CS330/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/var/folders/wq/56llthln30b_m_rns090kgyr0000gn/T/ipykernel_65013/3431795457.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/wq/56llthln30b_m_rns090kgyr0000gn/T/ipykernel_65013/3431795457.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.captions[idx])\n",
      "Epoch 0: 100%|██████████| 1/1 [02:32<00:00, 152.38s/it, ae_loss=271, vlm_loss=18.3]\n",
      "Epoch 1: 100%|██████████| 1/1 [02:34<00:00, 154.81s/it, ae_loss=267, vlm_loss=29.1]\n",
      "Epoch 2: 100%|██████████| 1/1 [02:34<00:00, 154.60s/it, ae_loss=244, vlm_loss=58.9]\n",
      "Epoch 3: 100%|██████████| 1/1 [02:29<00:00, 149.68s/it, ae_loss=216, vlm_loss=84.6]\n",
      "Epoch 4: 100%|██████████| 1/1 [02:35<00:00, 155.47s/it, ae_loss=191, vlm_loss=98.5]\n",
      "Epoch 5: 100%|██████████| 1/1 [02:41<00:00, 161.39s/it, ae_loss=170, vlm_loss=106]\n",
      "Epoch 6: 100%|██████████| 1/1 [02:23<00:00, 143.47s/it, ae_loss=151, vlm_loss=111]\n",
      "Epoch 7: 100%|██████████| 1/1 [02:34<00:00, 154.08s/it, ae_loss=136, vlm_loss=114]\n",
      "Epoch 8: 100%|██████████| 1/1 [02:37<00:00, 157.40s/it, ae_loss=123, vlm_loss=116]\n",
      "Epoch 9: 100%|██████████| 1/1 [02:33<00:00, 153.49s/it, ae_loss=113, vlm_loss=118]\n",
      "Epoch 10: 100%|██████████| 1/1 [02:38<00:00, 158.64s/it, ae_loss=106, vlm_loss=119]\n",
      "Epoch 11: 100%|██████████| 1/1 [02:25<00:00, 145.58s/it, ae_loss=102, vlm_loss=120]\n",
      "Epoch 12: 100%|██████████| 1/1 [02:28<00:00, 148.96s/it, ae_loss=99.3, vlm_loss=120]\n",
      "Epoch 13: 100%|██████████| 1/1 [02:36<00:00, 156.37s/it, ae_loss=97.8, vlm_loss=121]\n",
      "Epoch 14: 100%|██████████| 1/1 [02:37<00:00, 157.40s/it, ae_loss=97, vlm_loss=121]\n",
      "Epoch 15: 100%|██████████| 1/1 [02:42<00:00, 162.83s/it, ae_loss=96.5, vlm_loss=121]\n",
      "Epoch 16: 100%|██████████| 1/1 [02:23<00:00, 143.70s/it, ae_loss=96.2, vlm_loss=122]\n",
      "Epoch 17: 100%|██████████| 1/1 [02:32<00:00, 152.78s/it, ae_loss=95.8, vlm_loss=122]\n",
      "Epoch 18: 100%|██████████| 1/1 [02:50<00:00, 170.83s/it, ae_loss=95.3, vlm_loss=122]\n",
      "Epoch 19: 100%|██████████| 1/1 [02:29<00:00, 149.48s/it, ae_loss=94.7, vlm_loss=122]\n",
      "Epoch 20: 100%|██████████| 1/1 [02:38<00:00, 158.54s/it, ae_loss=94, vlm_loss=122]\n",
      "Epoch 21: 100%|██████████| 1/1 [02:30<00:00, 150.10s/it, ae_loss=93.4, vlm_loss=122]\n",
      "Epoch 22: 100%|██████████| 1/1 [02:30<00:00, 150.99s/it, ae_loss=93, vlm_loss=122]\n",
      "Epoch 23: 100%|██████████| 1/1 [02:33<00:00, 153.98s/it, ae_loss=92.6, vlm_loss=122]\n",
      "Epoch 24: 100%|██████████| 1/1 [02:33<00:00, 153.77s/it, ae_loss=92.3, vlm_loss=122]\n",
      "Epoch 25: 100%|██████████| 1/1 [02:41<00:00, 161.08s/it, ae_loss=92, vlm_loss=122]\n",
      "Epoch 26: 100%|██████████| 1/1 [02:33<00:00, 153.72s/it, ae_loss=91.6, vlm_loss=123]\n",
      "Epoch 27: 100%|██████████| 1/1 [02:35<00:00, 155.80s/it, ae_loss=91.3, vlm_loss=123]\n",
      "Epoch 28: 100%|██████████| 1/1 [02:34<00:00, 154.12s/it, ae_loss=91, vlm_loss=123]\n",
      "Epoch 29: 100%|██████████| 1/1 [02:37<00:00, 157.47s/it, ae_loss=90.6, vlm_loss=123]\n",
      "Epoch 0: 100%|██████████| 1/1 [02:44<00:00, 164.18s/it, ae_loss=90.2, vlm_loss=123]\n",
      "Epoch 1: 100%|██████████| 1/1 [02:29<00:00, 149.28s/it, ae_loss=89.8, vlm_loss=123]\n",
      "Epoch 2: 100%|██████████| 1/1 [02:35<00:00, 155.36s/it, ae_loss=89.5, vlm_loss=123]\n",
      "Epoch 3: 100%|██████████| 1/1 [02:34<00:00, 154.17s/it, ae_loss=89.3, vlm_loss=123]\n",
      "Epoch 4: 100%|██████████| 1/1 [02:43<00:00, 163.05s/it, ae_loss=89.1, vlm_loss=124]\n",
      "Epoch 5: 100%|██████████| 1/1 [02:39<00:00, 159.29s/it, ae_loss=88.9, vlm_loss=124]\n",
      "Epoch 6: 100%|██████████| 1/1 [02:33<00:00, 153.42s/it, ae_loss=88.7, vlm_loss=124]\n",
      "Epoch 7: 100%|██████████| 1/1 [02:35<00:00, 155.75s/it, ae_loss=88.5, vlm_loss=124]\n",
      "Epoch 8: 100%|██████████| 1/1 [02:29<00:00, 149.15s/it, ae_loss=88.3, vlm_loss=124]\n",
      "Epoch 9: 100%|██████████| 1/1 [02:37<00:00, 157.53s/it, ae_loss=88.2, vlm_loss=124]\n",
      "Epoch 10: 100%|██████████| 1/1 [02:36<00:00, 156.88s/it, ae_loss=88, vlm_loss=124]\n",
      "Epoch 11: 100%|██████████| 1/1 [02:34<00:00, 154.21s/it, ae_loss=87.8, vlm_loss=124]\n",
      "Epoch 12: 100%|██████████| 1/1 [02:40<00:00, 160.03s/it, ae_loss=87.6, vlm_loss=124]\n",
      "Epoch 13: 100%|██████████| 1/1 [02:30<00:00, 150.23s/it, ae_loss=87.4, vlm_loss=124]\n",
      "Epoch 14: 100%|██████████| 1/1 [02:34<00:00, 154.97s/it, ae_loss=87.2, vlm_loss=124]\n",
      "Epoch 15: 100%|██████████| 1/1 [02:37<00:00, 157.42s/it, ae_loss=87.1, vlm_loss=124]\n",
      "Epoch 16: 100%|██████████| 1/1 [02:27<00:00, 147.69s/it, ae_loss=86.9, vlm_loss=124]\n",
      "Epoch 17: 100%|██████████| 1/1 [02:33<00:00, 153.47s/it, ae_loss=86.7, vlm_loss=124]\n",
      "Epoch 18: 100%|██████████| 1/1 [02:31<00:00, 151.22s/it, ae_loss=86.5, vlm_loss=124]\n",
      "Epoch 19: 100%|██████████| 1/1 [02:34<00:00, 154.58s/it, ae_loss=86.2, vlm_loss=124]\n",
      "Epoch 20: 100%|██████████| 1/1 [02:44<00:00, 164.03s/it, ae_loss=86, vlm_loss=124]\n",
      "Epoch 21: 100%|██████████| 1/1 [02:32<00:00, 152.20s/it, ae_loss=85.8, vlm_loss=124]\n",
      "Epoch 22: 100%|██████████| 1/1 [02:26<00:00, 146.13s/it, ae_loss=85.6, vlm_loss=124]\n",
      "Epoch 23: 100%|██████████| 1/1 [02:24<00:00, 144.73s/it, ae_loss=85.4, vlm_loss=124]\n",
      "  0%|          | 0/1 [02:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m vlm_optimizer \u001b[38;5;241m=\u001b[39m AdamW([param \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mrequires_grad], lr\u001b[38;5;241m=\u001b[39mvlm_lr)\n\u001b[1;32m      7\u001b[0m ae_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(autoencoder\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mae_lr) \n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvlm_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mae_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvlm_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mae_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_epochs, vlm_lr, ae_lr, vlm_optimizer, ae_optimizer, device, save_every)\u001b[0m\n\u001b[1;32m     26\u001b[0m ae_loss \u001b[38;5;241m=\u001b[39m ae_criterion2(reconstructed_captions, captions, end_of_text_token_id)\n\u001b[1;32m     27\u001b[0m ae_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 28\u001b[0m \u001b[43mae_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# TODO: change loss as combination of vlm_loss and ae_loss instead of individual losses\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Update progress bar\u001b[39;00m\n\u001b[1;32m     33\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/CS330/lib/python3.9/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/CS330/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/CS330/lib/python3.9/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/CS330/lib/python3.9/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/CS330/lib/python3.9/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "vlm_lrs = [5e-5, 3e-4]#[1e-4, 1e-3, 3e-4, 3e-3]\n",
    "ae_lrs = [1e-3, 3e-4]#[1e-4, 1e-3, 3e-4, 3e-3]\n",
    "for vlm_lr in vlm_lrs:\n",
    "    for ae_lr in ae_lrs:\n",
    "        vlm_optimizer = AdamW([param for param in model.parameters() if param.requires_grad], lr=vlm_lr)\n",
    "        ae_optimizer = optim.Adam(autoencoder.parameters(), lr=ae_lr) \n",
    "        train(num_epochs, vlm_lr, ae_lr, vlm_optimizer, ae_optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory to save the model if it doesn't exist\n",
    "if not os.path.exists(\"models_auto_compress_online_data\"):\n",
    "    os.mkdir(\"models_auto_compress_online_data\")\n",
    "# save model checkpoint to models directory using current timestamp and date\n",
    "torch.save(model.state_dict(), f\"models_auto_compress_online_data/{time.strftime('%Y%m%d-%H%M%S')}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load latest model checkpoint among all the saved models\n",
    "latest_model = torch.load(max(glob.glob('models_auto_compress_online_data/*.pth'), key=os.path.getctime))\n",
    "# load the model with the latest checkpoint\n",
    "model.load_state_dict(latest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   64,  4077,  7779, 19584,  1306,   284,   257, 20799,   220, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  9283,  2137, 25635,   257,  7365,   379,   257,  2613,   220,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  9875,   318,  5055,   287,   257,  2214,   286,  8701,   220,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,   582,   318,  2712, 20790,   319,   257, 21558,  2184,   220,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,   582,   290,   257,  2415,  2712,   257,   983,   286,  1216,\n",
      "           271, 20963,   220, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  2415,   290,   257,   582,   389,  7722,  8237,   220, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  1976, 37052,  5055,   287,   257,   277,  5864,   287,  1989,\n",
      "           220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  8223, 40470,   287,   257,  2214,   351,   257,  5509,   220,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  6512, 49264,   319,  1353,   286,   257,  6512,  3745,   263,\n",
      "           220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  4512,   319,   257,  2610,  1474,   257, 13990,   220, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[  272, 20950,   351,   257,  1588, 21427,  5055,   319,   257, 13647,\n",
      "          2323,   220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64, 22259,  5044,   351,   257,   256, 21874,  6842,   319,   340,\n",
      "           220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  7480,   286,  2057,   351,  6174,    11, 44653,   290, 18821,\n",
      "           220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,   582,   287,   257,  6050,   290,  9839,  2045,   379,   465,\n",
      "          2685,  3072,   220, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64, 18757, 19584,   319,   262,  1735,   286,   257,  2975,   220,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  6842,  6155,   832,   257,  8222,   351,  5667,   220, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  7480,   286,  2057,   319,   257,  3084,   220, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  6569,  1630,  5586,   319,  1353,   286,   257, 18507,   220,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  1588, 12644, 24683,  7348,   832,   257, 40026,  6766,   220,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,   582,   287,   257,  6050,   290,  9839,  5486,   284,   257,\n",
      "          4315,   220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  7480,   286,  2057,   351,  6174,    11, 11464,   290, 13701,\n",
      "           220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,  1048, 14284,   257, 22647,  3526,   319,   257, 35614,   220,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64, 37370, 21223,  5055,  1306,   284,   257,  5509,   351,   257,\n",
      "         12835,   319,   340,   338,  1182,   220, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64,   582, 10311,   257,  6769,   319,  1353,   286,   257,  9053,\n",
      "          3526,   220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n",
      "tensor([[   64, 14043,   351,   257,  3996,    11,  5118,    11,   290,   257,\n",
      "          4324,   220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "[[ 64 582 257 257 257 257 257 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220 220\n",
      "  220 220]]\n"
     ]
    }
   ],
   "source": [
    "# Generate captions for the test dataset\n",
    "generated_captions_custom_model = []\n",
    "generated_captions_custom_model_pre_compression = []\n",
    "# Iterate over the dataset and generate captions\n",
    "for data in dataset:\n",
    "    image = data['image']\n",
    "    # use autoencoder to encode and decode the caption\n",
    "    caption = generate_caption(image)\n",
    "    generated_captions_custom_model_pre_compression.append(caption)\n",
    "    caption = tokenizer(caption, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    caption = caption['input_ids']\n",
    "    caption = caption.to(device)\n",
    "    print (caption)\n",
    "    compressed_caption = autoencoder.encode(caption)\n",
    "    compressed_caption = compressed_caption.to(device)\n",
    "    # print (compressed_caption)\n",
    "    reconstructed_caption = autoencoder.decode(compressed_caption)\n",
    "    reconstructed_caption = reconstructed_caption.to(device)\n",
    "    reconstructed_caption = reconstructed_caption.cpu()\n",
    "    reconstructed_caption = reconstructed_caption.detach().numpy()\n",
    "    reconstructed_caption = np.argmax(reconstructed_caption, axis=2)\n",
    "    print (reconstructed_caption)\n",
    "    reconstructed_caption = tokenizer.decode(reconstructed_caption[0], skip_special_tokens=True)\n",
    "    generated_captions_custom_model.append(reconstructed_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a green truck parked next to a curb ',\n",
       " 'a baseball player swinging a bat at a ball ',\n",
       " 'a cow is standing in a field of grass ',\n",
       " 'a man is playing tennis on a clay court ',\n",
       " 'a man and a woman playing a game of frisbee ',\n",
       " 'a woman and a man are drinking wine ',\n",
       " 'a zebra standing in a fenced in area ',\n",
       " 'a horse grazing in a field with a tree ',\n",
       " 'a bird perched on top of a bird feeder ',\n",
       " 'a train on a track near a fence ',\n",
       " 'an elephant with a large trunk standing on a dirt ground ',\n",
       " 'a stuffed animal with a teddy bear on it ',\n",
       " 'a plate of food with meat, broccoli and potatoes ',\n",
       " 'a man in a suit and tie looking at his cell phone ',\n",
       " 'a motorcycle parked on the side of a road ',\n",
       " 'a bear walking through a forest with leaves ',\n",
       " 'a plate of food on a table ',\n",
       " 'a remote control sitting on top of a couch ',\n",
       " 'a large jetliner flying through a cloudy sky ',\n",
       " 'a man in a suit and tie speaking to a crowd ',\n",
       " 'a plate of food with meat, rice and vegetables ',\n",
       " 'a person jumping a skateboard on a ledge ',\n",
       " \"a giraffe standing next to a tree with a leaf on it's head \",\n",
       " 'a man riding a wave on top of a surfboard ',\n",
       " 'a bedroom with a bed, chair, and a window ']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_captions_custom_model_pre_compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ',\n",
       " 'a man a a a a a                                                                                                                         ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_captions_custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bits Code     Value Symbol\n",
      "   7 0000000      0 'wave'\n",
      "   7 0000001      1 'window'\n",
      "   7 0000010      2 'wine'\n",
      "   7 0000011      3 'zebra'\n",
      "   6 000010       2 'woman'\n",
      "   6 000011       3 'food'\n",
      "   4 0001         1 'on'\n",
      "   5 00100        4 'in'\n",
      "   5 00101        5 'man'\n",
      "   6 001100      12 'plate'\n",
      "   6 001101      13 'to'\n",
      "   5 00111        7 'and'\n",
      "   2 01           1 'a'\n",
      "   6 100000      32 'top'\n",
      "   8 10000100   132 _EOF\n",
      "   8 10000101   133 'an'\n",
      "   8 10000110   134 'animal'\n",
      "   8 10000111   135 'are'\n",
      "   8 10001000   136 'area'\n",
      "   8 10001001   137 'ball'\n",
      "   7 1000101     69 'at'\n",
      "   8 10001100   140 'baseball'\n",
      "   8 10001101   141 'bat'\n",
      "   7 1000111     71 'bear'\n",
      "   8 10010000   144 'bed,'\n",
      "   8 10010001   145 'bedroom'\n",
      "   7 1001001     73 'bird'\n",
      "   8 10010100   148 'broccoli'\n",
      "   8 10010101   149 'cell'\n",
      "   8 10010110   150 'chair,'\n",
      "   8 10010111   151 'clay'\n",
      "   8 10011000   152 'cloudy'\n",
      "   8 10011001   153 'control'\n",
      "   8 10011010   154 'couch'\n",
      "   8 10011011   155 'court'\n",
      "   8 10011100   156 'cow'\n",
      "   8 10011101   157 'crowd'\n",
      "   8 10011110   158 'curb'\n",
      "   8 10011111   159 'dirt'\n",
      "   8 10100000   160 'drinking'\n",
      "   8 10100001   161 'elephant'\n",
      "   8 10100010   162 'feeder'\n",
      "   8 10100011   163 'fence'\n",
      "   8 10100100   164 'fenced'\n",
      "   8 10100101   165 'flying'\n",
      "   7 1010011     83 'field'\n",
      "   8 10101000   168 'forest'\n",
      "   8 10101001   169 'frisbee'\n",
      "   8 10101010   170 'game'\n",
      "   8 10101011   171 'giraffe'\n",
      "   8 10101100   172 'grass'\n",
      "   8 10101101   173 'grazing'\n",
      "   8 10101110   174 'green'\n",
      "   8 10101111   175 'ground'\n",
      "   8 10110000   176 'head'\n",
      "   8 10110001   177 'his'\n",
      "   8 10110010   178 'horse'\n",
      "   8 10110011   179 'it'\n",
      "   7 1011010     90 'is'\n",
      "   8 10110110   182 \"it's\"\n",
      "   8 10110111   183 'jetliner'\n",
      "   8 10111000   184 'jumping'\n",
      "   8 10111001   185 'leaf'\n",
      "   7 1011101     93 'large'\n",
      "   8 10111100   188 'leaves'\n",
      "   8 10111101   189 'ledge'\n",
      "   8 10111110   190 'looking'\n",
      "   8 10111111   191 'motorcycle'\n",
      "   7 1100000     96 'meat,'\n",
      "   8 11000010   194 'near'\n",
      "   8 11000011   195 'perched'\n",
      "   7 1100010     98 'next'\n",
      "   7 1100011     99 'parked'\n",
      "   8 11001000   200 'person'\n",
      "   8 11001001   201 'phone'\n",
      "   8 11001010   202 'player'\n",
      "   8 11001011   203 'potatoes'\n",
      "   7 1100110    102 'playing'\n",
      "   8 11001110   206 'remote'\n",
      "   8 11001111   207 'rice'\n",
      "   8 11010000   208 'riding'\n",
      "   8 11010001   209 'road'\n",
      "   8 11010010   210 'side'\n",
      "   8 11010011   211 'sitting'\n",
      "   8 11010100   212 'skateboard'\n",
      "   8 11010101   213 'sky'\n",
      "   8 11010110   214 'speaking'\n",
      "   8 11010111   215 'stuffed'\n",
      "   6 110110      54 'standing'\n",
      "   7 1101110    110 'suit'\n",
      "   8 11011110   222 'surfboard'\n",
      "   8 11011111   223 'swinging'\n",
      "   8 11100000   224 'table'\n",
      "   8 11100001   225 'teddy'\n",
      "   8 11100010   226 'tennis'\n",
      "   8 11100011   227 'the'\n",
      "   7 1110010    114 'through'\n",
      "   7 1110011    115 'tie'\n",
      "   8 11101000   232 'track'\n",
      "   8 11101001   233 'train'\n",
      "   7 1110101    117 'tree'\n",
      "   8 11101100   236 'truck'\n",
      "   8 11101101   237 'trunk'\n",
      "   8 11101110   238 'vegetables'\n",
      "   8 11101111   239 'walking'\n",
      "   5 11110       30 'with'\n",
      "   5 11111       31 'of'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 178)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode compressed dictionary word using manual huffman encoding\n",
    "def huffman_code(frequencies):\n",
    "    codec = HuffmanCodec.from_frequencies(frequencies)\n",
    "    # encoded = codec.encode(('emnlp here we come').split())\n",
    "    encoded = codec.encode(('a green truck parked next to a curb').split())\n",
    "    decoded = codec.decode(encoded)\n",
    "    # print(\"Encoded: \", encoded)\n",
    "    # print(\"Decoded: \", decoded)\n",
    "    codec.print_code_table()\n",
    "\n",
    "    return codec\n",
    "\n",
    "huffman_codec = huffman_code(encoding_dict)\n",
    "huffman_codec.get_code_table()['horse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace compressed_dict words occurring in the generated_captions_custom_model with their corresponding huffman encoding\n",
    "thing_to_send = []\n",
    "for caption in generated_captions_custom_model:\n",
    "    symbols = caption.split()\n",
    "    for symbol in symbols:\n",
    "        if symbol in huffman_codec.get_code_table().keys():\n",
    "            caption_new = caption.replace(symbol, str(huffman_codec.get_code_table()[symbol][1]))\n",
    "    thing_to_send.append(caption_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ', 'a man a a a a a                                                                                                                         ']\n"
     ]
    }
   ],
   "source": [
    "print(generated_captions_custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ',\n",
       " '1 m1n 1 1 1 1 1                                                                                                                         ']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "thing_to_send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare encoded generated_captions_custom_model + huffman encoding dictionary information with the original generated_captions to calculate compression ratio\n",
    "# todo: this is wrong here, but correct for manual\n",
    "compression_ratio = len(thing_to_send)/len(generated_captions_custom_model_pre_compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a green truck parked next to a curb  a green truck parked next to a curb  a green green parked a a a                                                                                                                         \n",
      "a man is walking down the street with a skateboard  a man is walking down the street with a skateboard  a man is is a a a a a a                                                                                                                      \n",
      "a baseball player swinging a bat at a ball  a baseball player swinging a bat at a ball  a man player a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a\n",
      "a cow is standing in a field of grass  a cow is standing in a field of grass  a man is standing a a a a                                                                                                                        \n",
      "a black dog sitting in the back of a truck  a black dog sitting in the back of a truck  a man dog in in a                                                                                                                          \n",
      "a man wearing a bow tie and glasses  a man wearing a bow tie and glasses  a man wearing a a                                                                                                                           \n",
      "a dining room table with a large bowl of food  a dining room table with a large bowl of food  a man room a a a a                                                                                                                         \n",
      "a man standing next to a wall with a bunch of guitars  a man standing next to a wall with a bunch of guitars  a man standing a a a a a a                                                                                                                       \n",
      "a man is playing tennis on a clay court  a man is playing tennis on a clay court  a man man is a a a a a                                                                                                                       \n"
     ]
    }
   ],
   "source": [
    "# print generated_captions and generated_captions_custom_model elementwise to compare the results\n",
    "for i in range(len(generated_captions)-1):\n",
    "    print (generated_captions[i], generated_captions_custom_model_pre_compression[i], generated_captions_custom_model[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "improve autoencoder architecture, use better semantic meaning preserving metric instead of simply cross entropy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
