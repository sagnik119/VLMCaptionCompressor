{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing manual compression of image captions on stale (offline) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bert==2.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: bitsandbytes==0.42.0 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 2)) (0.42.0)\n",
      "Requirement already satisfied: datasets==2.15.0 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 3)) (2.15.0)\n",
      "Requirement already satisfied: fiftyone==0.23.4 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 4)) (0.23.4)\n",
      "Requirement already satisfied: glob2==0.7 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 5)) (0.7)\n",
      "Requirement already satisfied: gradio==4.15.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 6)) (4.15.0)\n",
      "Requirement already satisfied: gradio_client==0.8.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 7)) (0.8.1)\n",
      "Requirement already satisfied: ipykernel==6.27.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 8)) (6.27.1)\n",
      "Requirement already satisfied: ipython==8.12.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 9)) (8.12.3)\n",
      "Requirement already satisfied: llava==0.0.1.dev0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 10)) (0.0.1.dev0)\n",
      "Requirement already satisfied: pandas==2.1.4 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 11)) (2.1.4)\n",
      "Requirement already satisfied: sacrebleu==1.5.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: safetensors==0.4.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 13)) (0.4.1)\n",
      "Requirement already satisfied: torch==2.1.1 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 14)) (2.1.1)\n",
      "Requirement already satisfied: torchaudio==2.1.1 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 15)) (2.1.1)\n",
      "Requirement already satisfied: torchvision==0.16.1 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 16)) (0.16.1)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 17)) (4.66.1)\n",
      "Requirement already satisfied: transformers==4.36.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 18)) (4.36.0)\n",
      "Requirement already satisfied: wandb==0.16.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 19)) (0.16.2)\n",
      "Requirement already satisfied: erlastic in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from bert==2.2.0->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: scipy in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 2)) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (1.26.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Library/Python/3.9/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0->-r requirements.txt (line 3)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (0.19.4)\n",
      "Requirement already satisfied: packaging in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (6.0.1)\n",
      "Requirement already satisfied: aiofiles in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (23.2.1)\n",
      "Requirement already satisfied: argcomplete in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (3.2.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (4.12.3)\n",
      "Requirement already satisfied: boto3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.34.29)\n",
      "Requirement already satisfied: cachetools in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (5.3.2)\n",
      "Requirement already satisfied: dacite<1.8.0,>=1.6.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: Deprecated in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.2.14)\n",
      "Requirement already satisfied: ftfy in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (6.1.3)\n",
      "Requirement already satisfied: humanize in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (4.9.0)\n",
      "Requirement already satisfied: hypercorn>=0.13.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: Jinja2>=3 in /Library/Python/3.9/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (3.1.2)\n",
      "Requirement already satisfied: kaleido!=0.2.1.post1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.2.1)\n",
      "Requirement already satisfied: matplotlib in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (3.8.2)\n",
      "Requirement already satisfied: mongoengine==0.24.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.24.2)\n",
      "Requirement already satisfied: motor>=2.5 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: Pillow>=6.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (10.1.0)\n",
      "Requirement already satisfied: plotly>=4.14 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (5.18.0)\n",
      "Requirement already satisfied: pprintpp in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: psutil in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (5.9.6)\n",
      "Requirement already satisfied: pymongo>=3.12 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (4.6.1)\n",
      "Requirement already satisfied: pytz in /Library/Python/3.9/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (2023.3.post1)\n",
      "Requirement already satisfied: regex in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (2023.10.3)\n",
      "Requirement already satisfied: retrying in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: scikit-image in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.22.0)\n",
      "Requirement already satisfied: setuptools in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (58.0.4)\n",
      "Requirement already satisfied: sseclient-py<2,>=1.7.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: sse-starlette<1,>=0.10.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.10.3)\n",
      "Requirement already satisfied: starlette>=0.24.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.27.0)\n",
      "Requirement already satisfied: strawberry-graphql==0.138.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.138.1)\n",
      "Requirement already satisfied: tabulate in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: xmltodict in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.13.0)\n",
      "Requirement already satisfied: universal-analytics-python3<2,>=1.0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: fiftyone-brain<0.17,>=0.16.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: fiftyone-db<2.0,>=0.4 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: voxel51-eta<0.13,>=0.12.4 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.12.4)\n",
      "Requirement already satisfied: opencv-python-headless in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (4.9.0.80)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (5.2.0)\n",
      "Requirement already satisfied: fastapi in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.105.0)\n",
      "Requirement already satisfied: ffmpy in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.3.1)\n",
      "Requirement already satisfied: httpx in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.24.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (6.1.1)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Library/Python/3.9/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (2.1.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (3.9.12)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (2.5.3)\n",
      "Requirement already satisfied: pydub in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.0.6)\n",
      "Requirement already satisfied: ruff>=0.1.7 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.1.14)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (4.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.22.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio_client==0.8.1->-r requirements.txt (line 7)) (11.0.3)\n",
      "Requirement already satisfied: appnope in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (0.1.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (1.5.8)\n",
      "Requirement already satisfied: pyzmq>=20 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (5.14.0)\n",
      "Requirement already satisfied: backcall in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (0.19.1)\n",
      "Requirement already satisfied: pickleshare in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Python/3.9/site-packages (from pandas==2.1.4->-r requirements.txt (line 11)) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Python/3.9/site-packages (from pandas==2.1.4->-r requirements.txt (line 11)) (2023.3)\n",
      "Requirement already satisfied: portalocker in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from sacrebleu==1.5.0->-r requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: filelock in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from torch==2.1.1->-r requirements.txt (line 14)) (3.13.1)\n",
      "Requirement already satisfied: sympy in /Library/Python/3.9/site-packages (from torch==2.1.1->-r requirements.txt (line 14)) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Python/3.9/site-packages (from torch==2.1.1->-r requirements.txt (line 14)) (3.2.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from transformers==4.36.0->-r requirements.txt (line 18)) (0.15.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (3.1.41)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (1.39.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (1.3.3)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (4.25.2)\n",
      "Requirement already satisfied: graphql-core<3.3.0,>=3.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from strawberry-graphql==0.138.1->fiftyone==0.23.4->-r requirements.txt (line 4)) (3.2.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from altair<6.0,>=4.2.0->gradio==4.15.0->-r requirements.txt (line 6)) (4.21.1)\n",
      "Requirement already satisfied: toolz in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from altair<6.0,>=4.2.0->gradio==4.15.0->-r requirements.txt (line 6)) (0.12.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb==0.16.2->-r requirements.txt (line 19)) (1.15.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.16.2->-r requirements.txt (line 19)) (4.0.11)\n",
      "Requirement already satisfied: h11 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: h2>=3.1.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (4.1.0)\n",
      "Requirement already satisfied: priority in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: taskgroup in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.0.0a4)\n",
      "Requirement already satisfied: tomli in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.0.1)\n",
      "Requirement already satisfied: wsproto>=0.14.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from importlib-resources<7.0,>=1.3->gradio==4.15.0->-r requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jedi>=0.16->ipython==8.12.3->-r requirements.txt (line 9)) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel==6.27.1->-r requirements.txt (line 8)) (7.0.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.27.1->-r requirements.txt (line 8)) (4.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from matplotlib->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from matplotlib->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from matplotlib->fiftyone==0.23.4->-r requirements.txt (line 4)) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from matplotlib->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from matplotlib->fiftyone==0.23.4->-r requirements.txt (line 4)) (3.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3->ipython==8.12.3->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from plotly>=4.14->fiftyone==0.23.4->-r requirements.txt (line 4)) (8.2.3)\n",
      "Requirement already satisfied: wcwidth in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython==8.12.3->-r requirements.txt (line 9)) (0.2.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.0->gradio==4.15.0->-r requirements.txt (line 6)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.0->gradio==4.15.0->-r requirements.txt (line 6)) (2.14.6)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from pymongo>=3.12->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets==2.15.0->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets==2.15.0->-r requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets==2.15.0->-r requirements.txt (line 3)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets==2.15.0->-r requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from starlette>=0.24.0->fiftyone==0.23.4->-r requirements.txt (line 4)) (3.7.1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (13.7.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from httpx->gradio==4.15.0->-r requirements.txt (line 6)) (0.17.3)\n",
      "Requirement already satisfied: sniffio in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from httpx->gradio==4.15.0->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: future in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.18.2)\n",
      "Requirement already satisfied: jsonlines in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: py7zr in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.20.8)\n",
      "Requirement already satisfied: rarfile in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (4.1)\n",
      "Requirement already satisfied: sortedcontainers in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: tzlocal in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (5.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.5)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.29 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from boto3->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.34.29)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from boto3->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from boto3->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from Deprecated->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from scikit-image->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from scikit-image->fiftyone==0.23.4->-r requirements.txt (line 4)) (2023.12.9)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from scikit-image->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from scikit-learn->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from scikit-learn->fiftyone==0.23.4->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython==8.12.3->-r requirements.txt (line 9)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython==8.12.3->-r requirements.txt (line 9)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython==8.12.3->-r requirements.txt (line 9)) (0.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Python/3.9/site-packages (from sympy->torch==2.1.1->-r requirements.txt (line 14)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.16.2->-r requirements.txt (line 19)) (5.0.1)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.15.0->-r requirements.txt (line 6)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.15.0->-r requirements.txt (line 6)) (0.32.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.15.0->-r requirements.txt (line 6)) (0.17.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: texttable in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (3.20.0)\n",
      "Requirement already satisfied: pyzstd>=0.15.9 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.15.9)\n",
      "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.0.2)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.2.3)\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer, BitsAndBytesConfig, AutoProcessor, LlavaForConditionalGeneration\n",
    "from transformers import AdamW\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from collections import Counter\n",
    "import fiftyone\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "\n",
    "# uncommon features  - events of interest\n",
    "# loss less compression -  sudden more bits indicates anomaly can be flagged, alerts when anomaly detected - may shift to lossy video streaming\n",
    "# lossy compression of noisy data varying distortion rate - accuracy is increasing\n",
    "# video to video lossy reconstruction possibility\n",
    "# image frame to image frame on a need basis - human satisfaction metric, GPT based comparison, RLHF based comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the GPU!\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "    # torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model and its components\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "# # Loading the above for LlavVA\n",
    "# model_llava = LlavaForConditionalGeneration.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "# processor_llava = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 40670/40670 [00:00<00:00, 546344.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset (for example, a subset of the COCO dataset)\n",
    "# TODO: Potential datasets with repetitive nature that can be used: MS COCO, Flickr30k, Visual Genome, SBU Captions - get correlated datasets from Nikil\n",
    "\n",
    "# load small part of the coco dataset from all the .jpg images in datasets/mscoco/test2015\n",
    "dataset = load_dataset(\"datasets/mscoco/test2017/\", split=\"train[:100]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use different values of max_length and try out results\n",
    "\n",
    "def generate_caption_with_logits(image, max_length=15):\n",
    "    # Prepare the inputs\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n",
    "    pixel_values = inputs.pixel_values\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Perform a forward pass to get the logits\n",
    "        encoder_outputs = model.encoder(pixel_values=pixel_values)\n",
    "        encoder_hidden_states = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Prepare decoder input_ids. Typically, you start with the start-of-sentence token\n",
    "        decoder_input_ids = torch.tensor([tokenizer.bos_token_id]).unsqueeze(0).to(encoder_hidden_states.device)\n",
    "        decoder_attention_mask = torch.ones_like(decoder_input_ids)\n",
    "        \n",
    "        # Initialize an empty tensor for logits (for simplicity, accumulating logits for each step)\n",
    "        logits_list = []\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            decoder_outputs = model.decoder(input_ids=decoder_input_ids,\n",
    "                                            attention_mask=decoder_attention_mask,\n",
    "                                            encoder_hidden_states=encoder_hidden_states)\n",
    "            logits = decoder_outputs.logits[:, -1, :]  # Get the logits for the last token generated\n",
    "            logits_list.append(logits)\n",
    "            \n",
    "            predicted_id = torch.argmax(logits, dim=-1).unsqueeze(-1)\n",
    "            # Check if EOS token is generated\n",
    "            if predicted_id[0, 0] == tokenizer.eos_token_id:\n",
    "                print (\"EOS has been generated\")\n",
    "                # break # since model.generate() does this automatically\n",
    "            \n",
    "            # Append predicted token ID to decoder_input_ids for generating next token\n",
    "            decoder_input_ids = torch.cat([decoder_input_ids, predicted_id], dim=-1)\n",
    "            decoder_attention_mask = torch.cat([decoder_attention_mask, torch.ones_like(predicted_id).to(device)], dim=-1)\n",
    "            \n",
    "        # Concatenate logits from each step to get the final logits tensor\n",
    "        # make all elements of logits_list 3D by adding a dimension in the middle\n",
    "        logits_list = [logits.unsqueeze(1) for logits in logits_list]\n",
    "        logits = torch.cat(logits_list, dim=1)\n",
    "        # add logic to repeat the remaining number of (127-i) tokens with EOS token logits (simply repeat the last token logits) to make it length 128\n",
    "\n",
    "        # Decode the generated token IDs to get the caption\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        caption = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "    return logits, predicted_ids, caption\n",
    "\n",
    "# Example usage\n",
    "# image: A PIL image or a tensor representing your input image\n",
    "# logits, predicted_ids, caption = generate_caption_with_logits(image, model, feature_extractor, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "torch.Size([100, 15, 50257])\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the dataset and generate captions\n",
    "generated_captions = []\n",
    "generated_logits = []\n",
    "generated_predicted_ids = []\n",
    "\n",
    "for data in dataset:\n",
    "    image = data['image']\n",
    "    logits, predicted_ids, caption = generate_caption_with_logits(image)\n",
    "    generated_captions.append(caption)\n",
    "    generated_logits.append(logits)\n",
    "    generated_predicted_ids.append(predicted_ids)\n",
    "\n",
    "# concatenate generated logits along first dimension to make 3D tensor\n",
    "generated_logits = torch.cat(generated_logits, dim=0)\n",
    "print (generated_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a green truck parked next to a curb a green truck parked next',\n",
       " 'a baseball player swinging a bat at a ball a baseball player swinging',\n",
       " 'a cow is standing in a field of grass a cow is standing',\n",
       " 'a man is playing tennis on a clay court a man is playing',\n",
       " 'a man and a woman playing a game of frisbee a',\n",
       " 'a woman and a man are drinking wine people are sitting at a',\n",
       " 'a zebra standing in a fenced in area a zebra',\n",
       " 'a horse grazing in a field with a tree a horse grazing in',\n",
       " 'a bird perched on top of a bird feeder a bird sitting',\n",
       " 'a train on a track near a fence a train on a track',\n",
       " 'an elephant with a large trunk standing on a dirt ground a elephant',\n",
       " 'a stuffed animal with a teddy bear on it a teddy',\n",
       " 'a plate of food with meat, broccoli and potatoes a plate of',\n",
       " 'a man in a suit and tie looking at his cell phone a',\n",
       " 'a motorcycle parked on the side of a road a motorcycle is parked',\n",
       " 'a bear walking through a forest with leaves a black bear standing in',\n",
       " 'a plate of food on a table a hot dog on a bun',\n",
       " 'a remote control sitting on top of a couch a remote control sitting',\n",
       " 'a large jetliner flying through a cloudy sky a large jetliner',\n",
       " 'a man in a suit and tie speaking to a crowd a man',\n",
       " 'a plate of food with meat, rice and vegetables a plate of',\n",
       " 'a person jumping a skateboard on a ledge a person jumping a',\n",
       " \"a giraffe standing next to a tree with a leaf on it's head\",\n",
       " 'a man riding a wave on top of a surfboard a sur',\n",
       " 'a bedroom with a bed, chair, and a window a room',\n",
       " \"a clock tower with a clock on it's side a clock tower\",\n",
       " 'a large brick building with a clock tower a large building with a',\n",
       " 'a woman is sitting on the sidewalk while a man walks by people',\n",
       " 'three children sitting at a table with a laptop people sitting at a',\n",
       " 'a young girl skiing down a snow covered slope a person on a',\n",
       " 'a small boat docked in a body of water a small boat',\n",
       " 'a computer mouse sitting on top of a keyboard a computer mouse sitting',\n",
       " 'three women sitting at a table with plates of food people sitting around',\n",
       " 'people are standing outside of a bus people are standing in front of',\n",
       " 'a man and a woman are standing in a living room a man',\n",
       " 'a large jetliner sitting on top of an airport tarmac a',\n",
       " 'a baby laying on the floor next to a stove a child is',\n",
       " 'a desk with a laptop, monitor, keyboard and mouse a laptop',\n",
       " 'a zebra standing in a fenced in area a zebra',\n",
       " 'a row of parked motorcycles with a rack of them a row of',\n",
       " 'a fire hydrant is covered in snow by a tree a fire',\n",
       " 'a woman in a white dress playing tennis a woman in a white',\n",
       " 'a woman holding a cell phone in her hand a woman holding a',\n",
       " 'a parking meter with a black stripe on it a parking meter with',\n",
       " 'a woman sitting in a market with a bunch of fruit a woman',\n",
       " 'a plane flying through a cloud filled sky a plane flying through a',\n",
       " 'a woman standing on a bed with a dress on a woman is',\n",
       " 'a large jetliner sitting on top of an airport runway a blue',\n",
       " 'a living room with a couch, television and a fire place a',\n",
       " 'a cat wearing a tie and a shirt a cat wearing a tie',\n",
       " 'a woman in a black dress is petting a black dog a',\n",
       " 'people walking down a street people walking down a street people',\n",
       " 'a couple sitting on a bench with a sky background a man and',\n",
       " 'a double decker bus is driving down the street a double deck',\n",
       " 'a row of benches sitting on top of a pier a row of',\n",
       " 'a tennis player is swinging a racket at a ball a tennis player',\n",
       " 'a baby sitting in a high chair eating carrots a baby sitting in',\n",
       " 'a street sign on a pole in front of a building a street',\n",
       " 'a stop sign with graffiti on it a stop sign with a sticker',\n",
       " 'motorcycles parked in a row motorcycles are parked in',\n",
       " 'a kitchen with a stove, sink, and refrigerator a kitchen with',\n",
       " 'two cats are laying on a bed with a dog a cat and',\n",
       " 'a giraffe standing in the middle of a field a giraffe',\n",
       " 'a pizza with cheese and olives on a plate a pizza with',\n",
       " 'a cat is sitting on the floor in a living room a cat',\n",
       " 'two men in a room with a man in a suit a man',\n",
       " 'a flock of birds flying over a flock of birds flying a flock',\n",
       " 'a piece of cake with strawberries on a plate a piece of cake',\n",
       " 'a giraffe standing in a field next to a tree a gir',\n",
       " 'a cat sitting in a window sill looking out a cat sitting in',\n",
       " 'a man riding a motorcycle on a race track a man on a',\n",
       " 'a motorcycle is parked on the side of the road a man riding',\n",
       " 'a cat laying on a laptop computer a cat laying on a bed',\n",
       " 'a woman standing in the dirt with a group of people people walking',\n",
       " 'a man hitting a tennis ball with a tennis racket a man is',\n",
       " 'a woman is eating a hot dog with ketchup a woman is',\n",
       " 'a traffic light on a city street a man is standing on a',\n",
       " 'a street sign on a pole in front of a building a street',\n",
       " 'a baseball game in progress with the batter up to plate a baseball',\n",
       " 'a teddy bear sitting on a chair in a room a t',\n",
       " 'a man holding a giant kite in his hand a man holding',\n",
       " 'a dog laying on a blanket on a table a dog laying on',\n",
       " 'a bedroom with a bed, chair, and a desk a room',\n",
       " 'a red and white cupcake sitting in an oven a small oven',\n",
       " 'a kitchen counter with a vase of flowers and a bottle of water ',\n",
       " 'a bathroom with a toilet and a sink a small bathroom with a',\n",
       " 'a bathroom with a sink, mirror, and bath tub a bathroom',\n",
       " 'a vase with a plant in it a small vase with',\n",
       " 'a cat laying on a rug next to a dog a cat laying',\n",
       " 'a large elephant walking through a grassy field a large elephant walking',\n",
       " 'a train on a track near a platform a train on a train',\n",
       " 'a kitchen with a sink, stove, refrigerator and a dishwasher ',\n",
       " 'a kitchen with a table, a table cloth, a table cloth, a',\n",
       " 'a man standing in front of a tv playing a video game a',\n",
       " 'a man standing next to a parking meter a man standing next to',\n",
       " 'a plate of food with broccoli and meat a plate of food with',\n",
       " 'a man on a skateboard doing a trick a man on a',\n",
       " 'an elephant standing in a grassy field a large elephant standing in',\n",
       " 'a flock of sheep standing next to a gas station a sheep standing',\n",
       " 'three birds perched on a wooden post two birds perched on a fence']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_encoding_dict(captions, encoding_dict):\n",
    "    for caption in captions:\n",
    "        words = caption.split() # splitting the caption into words - pretty bad strategy since we are currently splitting into tokens\n",
    "        encoding_dict.update(words) # purpose of update is to add the words to the dictionary if they don't exist\n",
    "    return encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'a': 327, 'on': 50, 'with': 45, 'in': 41, 'of': 40, 'man': 27, 'sitting': 23, 'standing': 22, 'and': 22, 'is': 18, 'woman': 16, 'people': 11, 'cat': 11, 'to': 10, 'large': 10, 'plate': 10, 'the': 10, 'next': 9, 'parked': 8, 'laying': 8, 'street': 8, 'at': 7, 'are': 7, 'top': 7, 'dog': 7, 'room': 7, 'field': 6, 'tennis': 6, 'elephant': 6, 'food': 6, 'walking': 6, 'table': 6, 'playing': 5, 'train': 5, 'an': 5, 'through': 5, 'flying': 5, 'small': 5, 'row': 5, 'kitchen': 5, 'baseball': 4, 'player': 4, 'zebra': 4, 'tree': 4, 'track': 4, 'bear': 4, 'it': 4, 'tie': 4, 'motorcycle': 4, 'black': 4, 'jetliner': 4, 'giraffe': 4, 'clock': 4, 'building': 4, 'down': 4, 'front': 4, 'holding': 4, 'sign': 4, 'flock': 4, 'birds': 4, 'bathroom': 4, 'swinging': 3, 'ball': 3, 'game': 3, 'bird': 3, 'perched': 3, 'teddy': 3, 'suit': 3, 'side': 3, 'sky': 3, 'person': 3, 'riding': 3, 'tower': 3, 'three': 3, 'laptop': 3, 'computer': 3, 'mouse': 3, 'living': 3, 'baby': 3, 'motorcycles': 3, 'fire': 3, 'white': 3, 'dress': 3, 'parking': 3, 'meter': 3, 'bed': 3, 'sink,': 3, 'two': 3, 'vase': 3, 'green': 2, 'truck': 2, 'cow': 2, 'fenced': 2, 'area': 2, 'horse': 2, 'grazing': 2, 'near': 2, 'fence': 2, 'dirt': 2, 'meat,': 2, 'broccoli': 2, 'looking': 2, 'his': 2, 'cell': 2, 'phone': 2, 'road': 2, 'hot': 2, 'remote': 2, 'control': 2, 'jumping': 2, 'skateboard': 2, \"it's\": 2, 'bedroom': 2, 'bed,': 2, 'chair,': 2, 'window': 2, 'by': 2, 'snow': 2, 'covered': 2, 'boat': 2, 'water': 2, 'keyboard': 2, 'bus': 2, 'airport': 2, 'floor': 2, 'desk': 2, 'hand': 2, 'plane': 2, 'wearing': 2, 'double': 2, 'racket': 2, 'chair': 2, 'eating': 2, 'pole': 2, 'stop': 2, 'stove,': 2, 'refrigerator': 2, 'pizza': 2, 'piece': 2, 'cake': 2, 'oven': 2, 'grassy': 2, 'cloth,': 2, 'sheep': 2, 'curb': 1, 'bat': 1, 'grass': 1, 'clay': 1, 'court': 1, 'frisbee': 1, 'drinking': 1, 'wine': 1, 'feeder': 1, 'trunk': 1, 'ground': 1, 'stuffed': 1, 'animal': 1, 'potatoes': 1, 'forest': 1, 'leaves': 1, 'bun': 1, 'couch': 1, 'cloudy': 1, 'speaking': 1, 'crowd': 1, 'rice': 1, 'vegetables': 1, 'ledge': 1, 'leaf': 1, 'head': 1, 'wave': 1, 'surfboard': 1, 'sur': 1, 'brick': 1, 'sidewalk': 1, 'while': 1, 'walks': 1, 'children': 1, 'young': 1, 'girl': 1, 'skiing': 1, 'slope': 1, 'docked': 1, 'body': 1, 'women': 1, 'plates': 1, 'around': 1, 'outside': 1, 'tarmac': 1, 'stove': 1, 'child': 1, 'laptop,': 1, 'monitor,': 1, 'rack': 1, 'them': 1, 'hydrant': 1, 'her': 1, 'stripe': 1, 'market': 1, 'bunch': 1, 'fruit': 1, 'cloud': 1, 'filled': 1, 'runway': 1, 'blue': 1, 'couch,': 1, 'television': 1, 'place': 1, 'shirt': 1, 'petting': 1, 'couple': 1, 'bench': 1, 'background': 1, 'decker': 1, 'driving': 1, 'deck': 1, 'benches': 1, 'pier': 1, 'high': 1, 'carrots': 1, 'graffiti': 1, 'sticker': 1, 'cats': 1, 'middle': 1, 'cheese': 1, 'olives': 1, 'men': 1, 'over': 1, 'strawberries': 1, 'gir': 1, 'sill': 1, 'out': 1, 'race': 1, 'group': 1, 'hitting': 1, 'ketchup': 1, 'traffic': 1, 'light': 1, 'city': 1, 'progress': 1, 'batter': 1, 'up': 1, 't': 1, 'giant': 1, 'kite': 1, 'blanket': 1, 'red': 1, 'cupcake': 1, 'counter': 1, 'flowers': 1, 'bottle': 1, 'toilet': 1, 'sink': 1, 'mirror,': 1, 'bath': 1, 'tub': 1, 'plant': 1, 'rug': 1, 'platform': 1, 'dishwasher': 1, 'table,': 1, 'tv': 1, 'video': 1, 'meat': 1, 'doing': 1, 'trick': 1, 'gas': 1, 'station': 1, 'wooden': 1, 'post': 1})\n",
      "{'a': 1.3337126143073539, 'green': 6.430525604644662, 'truck': 6.430525604644662, 'parked': 5.044231243524771, 'next': 4.926448207868388, 'to': 4.821087692210561, 'curb': 7.123672785204607, 'baseball': 5.737378424084716, 'player': 5.737378424084716, 'swinging': 6.025060496536497, 'bat': 7.123672785204607, 'at': 5.177762636149294, 'ball': 6.025060496536497, 'cow': 6.430525604644662, 'is': 4.233301027308443, 'standing': 4.032630331846291, 'in': 3.4101007185002996, 'field': 5.331913315976552, 'of': 3.434793331090671, 'grass': 7.123672785204607, 'man': 3.827835919200278, 'playing': 5.514234872770507, 'tennis': 5.331913315976552, 'on': 3.211649779776461, 'clay': 7.123672785204607, 'court': 7.123672785204607, 'and': 4.032630331846291, 'woman': 4.351084062964826, 'game': 6.025060496536497, 'frisbee': 7.123672785204607, 'are': 5.177762636149294, 'drinking': 7.123672785204607, 'wine': 7.123672785204607, 'people': 4.7257775124062364, 'sitting': 3.9881785692754574, 'zebra': 5.737378424084716, 'fenced': 6.430525604644662, 'area': 6.430525604644662, 'horse': 6.430525604644662, 'grazing': 6.430525604644662, 'with': 3.3170102954342875, 'tree': 5.737378424084716, 'bird': 6.025060496536497, 'perched': 6.025060496536497, 'top': 5.177762636149294, 'feeder': 7.123672785204607, 'train': 5.514234872770507, 'track': 5.737378424084716, 'near': 6.430525604644662, 'fence': 6.430525604644662, 'an': 5.514234872770507, 'elephant': 5.331913315976552, 'large': 4.821087692210561, 'trunk': 7.123672785204607, 'dirt': 6.430525604644662, 'ground': 7.123672785204607, 'stuffed': 7.123672785204607, 'animal': 7.123672785204607, 'teddy': 6.025060496536497, 'bear': 5.737378424084716, 'it': 5.737378424084716, 'plate': 4.821087692210561, 'food': 5.331913315976552, 'meat,': 6.430525604644662, 'broccoli': 6.430525604644662, 'potatoes': 7.123672785204607, 'suit': 6.025060496536497, 'tie': 5.737378424084716, 'looking': 6.430525604644662, 'his': 6.430525604644662, 'cell': 6.430525604644662, 'phone': 6.430525604644662, 'motorcycle': 5.737378424084716, 'the': 4.821087692210561, 'side': 6.025060496536497, 'road': 6.430525604644662, 'walking': 5.331913315976552, 'through': 5.514234872770507, 'forest': 7.123672785204607, 'leaves': 7.123672785204607, 'black': 5.737378424084716, 'table': 5.331913315976552, 'hot': 6.430525604644662, 'dog': 5.177762636149294, 'bun': 7.123672785204607, 'remote': 6.430525604644662, 'control': 6.430525604644662, 'couch': 7.123672785204607, 'jetliner': 5.737378424084716, 'flying': 5.514234872770507, 'cloudy': 7.123672785204607, 'sky': 6.025060496536497, 'speaking': 7.123672785204607, 'crowd': 7.123672785204607, 'rice': 7.123672785204607, 'vegetables': 7.123672785204607, 'person': 6.025060496536497, 'jumping': 6.430525604644662, 'skateboard': 6.430525604644662, 'ledge': 7.123672785204607, 'giraffe': 5.737378424084716, 'leaf': 7.123672785204607, \"it's\": 6.430525604644662, 'head': 7.123672785204607, 'riding': 6.025060496536497, 'wave': 7.123672785204607, 'surfboard': 7.123672785204607, 'sur': 7.123672785204607, 'bedroom': 6.430525604644662, 'bed,': 6.430525604644662, 'chair,': 6.430525604644662, 'window': 6.430525604644662, 'room': 5.177762636149294, 'clock': 5.737378424084716, 'tower': 6.025060496536497, 'brick': 7.123672785204607, 'building': 5.737378424084716, 'sidewalk': 7.123672785204607, 'while': 7.123672785204607, 'walks': 7.123672785204607, 'by': 6.430525604644662, 'three': 6.025060496536497, 'children': 7.123672785204607, 'laptop': 6.025060496536497, 'young': 7.123672785204607, 'girl': 7.123672785204607, 'skiing': 7.123672785204607, 'down': 5.737378424084716, 'snow': 6.430525604644662, 'covered': 6.430525604644662, 'slope': 7.123672785204607, 'small': 5.514234872770507, 'boat': 6.430525604644662, 'docked': 7.123672785204607, 'body': 7.123672785204607, 'water': 6.430525604644662, 'computer': 6.025060496536497, 'mouse': 6.025060496536497, 'keyboard': 6.430525604644662, 'women': 7.123672785204607, 'plates': 7.123672785204607, 'around': 7.123672785204607, 'outside': 7.123672785204607, 'bus': 6.430525604644662, 'front': 5.737378424084716, 'living': 6.025060496536497, 'airport': 6.430525604644662, 'tarmac': 7.123672785204607, 'baby': 6.025060496536497, 'laying': 5.044231243524771, 'floor': 6.430525604644662, 'stove': 7.123672785204607, 'child': 7.123672785204607, 'desk': 6.430525604644662, 'laptop,': 7.123672785204607, 'monitor,': 7.123672785204607, 'row': 5.514234872770507, 'motorcycles': 6.025060496536497, 'rack': 7.123672785204607, 'them': 7.123672785204607, 'fire': 6.025060496536497, 'hydrant': 7.123672785204607, 'white': 6.025060496536497, 'dress': 6.025060496536497, 'holding': 5.737378424084716, 'her': 7.123672785204607, 'hand': 6.430525604644662, 'parking': 6.025060496536497, 'meter': 6.025060496536497, 'stripe': 7.123672785204607, 'market': 7.123672785204607, 'bunch': 7.123672785204607, 'fruit': 7.123672785204607, 'plane': 6.430525604644662, 'cloud': 7.123672785204607, 'filled': 7.123672785204607, 'bed': 6.025060496536497, 'runway': 7.123672785204607, 'blue': 7.123672785204607, 'couch,': 7.123672785204607, 'television': 7.123672785204607, 'place': 7.123672785204607, 'cat': 4.7257775124062364, 'wearing': 6.430525604644662, 'shirt': 7.123672785204607, 'petting': 7.123672785204607, 'street': 5.044231243524771, 'couple': 7.123672785204607, 'bench': 7.123672785204607, 'background': 7.123672785204607, 'double': 6.430525604644662, 'decker': 7.123672785204607, 'driving': 7.123672785204607, 'deck': 7.123672785204607, 'benches': 7.123672785204607, 'pier': 7.123672785204607, 'racket': 6.430525604644662, 'high': 7.123672785204607, 'chair': 6.430525604644662, 'eating': 6.430525604644662, 'carrots': 7.123672785204607, 'sign': 5.737378424084716, 'pole': 6.430525604644662, 'stop': 6.430525604644662, 'graffiti': 7.123672785204607, 'sticker': 7.123672785204607, 'kitchen': 5.514234872770507, 'stove,': 6.430525604644662, 'sink,': 6.025060496536497, 'refrigerator': 6.430525604644662, 'two': 6.025060496536497, 'cats': 7.123672785204607, 'middle': 7.123672785204607, 'pizza': 6.430525604644662, 'cheese': 7.123672785204607, 'olives': 7.123672785204607, 'men': 7.123672785204607, 'flock': 5.737378424084716, 'birds': 5.737378424084716, 'over': 7.123672785204607, 'piece': 6.430525604644662, 'cake': 6.430525604644662, 'strawberries': 7.123672785204607, 'gir': 7.123672785204607, 'sill': 7.123672785204607, 'out': 7.123672785204607, 'race': 7.123672785204607, 'group': 7.123672785204607, 'hitting': 7.123672785204607, 'ketchup': 7.123672785204607, 'traffic': 7.123672785204607, 'light': 7.123672785204607, 'city': 7.123672785204607, 'progress': 7.123672785204607, 'batter': 7.123672785204607, 'up': 7.123672785204607, 't': 7.123672785204607, 'giant': 7.123672785204607, 'kite': 7.123672785204607, 'blanket': 7.123672785204607, 'red': 7.123672785204607, 'cupcake': 7.123672785204607, 'oven': 6.430525604644662, 'counter': 7.123672785204607, 'vase': 6.025060496536497, 'flowers': 7.123672785204607, 'bottle': 7.123672785204607, 'bathroom': 5.737378424084716, 'toilet': 7.123672785204607, 'sink': 7.123672785204607, 'mirror,': 7.123672785204607, 'bath': 7.123672785204607, 'tub': 7.123672785204607, 'plant': 7.123672785204607, 'rug': 7.123672785204607, 'grassy': 6.430525604644662, 'platform': 7.123672785204607, 'dishwasher': 7.123672785204607, 'table,': 7.123672785204607, 'cloth,': 6.430525604644662, 'tv': 7.123672785204607, 'video': 7.123672785204607, 'meat': 7.123672785204607, 'doing': 7.123672785204607, 'trick': 7.123672785204607, 'sheep': 6.430525604644662, 'gas': 7.123672785204607, 'station': 7.123672785204607, 'wooden': 7.123672785204607, 'post': 7.123672785204607}\n",
      "{'a': 0.003048780487804878, 'green': 0.3333333333333333, 'truck': 0.3333333333333333, 'parked': 0.1111111111111111, 'next': 0.1, 'to': 0.09090909090909091, 'curb': 0.5, 'baseball': 0.2, 'player': 0.2, 'swinging': 0.25, 'bat': 0.5, 'at': 0.125, 'ball': 0.25, 'cow': 0.3333333333333333, 'is': 0.05263157894736842, 'standing': 0.043478260869565216, 'in': 0.023809523809523808, 'field': 0.14285714285714285, 'of': 0.024390243902439025, 'grass': 0.5, 'man': 0.03571428571428571, 'playing': 0.16666666666666666, 'tennis': 0.14285714285714285, 'on': 0.0196078431372549, 'clay': 0.5, 'court': 0.5, 'and': 0.043478260869565216, 'woman': 0.058823529411764705, 'game': 0.25, 'frisbee': 0.5, 'are': 0.125, 'drinking': 0.5, 'wine': 0.5, 'people': 0.08333333333333333, 'sitting': 0.041666666666666664, 'zebra': 0.2, 'fenced': 0.3333333333333333, 'area': 0.3333333333333333, 'horse': 0.3333333333333333, 'grazing': 0.3333333333333333, 'with': 0.021739130434782608, 'tree': 0.2, 'bird': 0.25, 'perched': 0.25, 'top': 0.125, 'feeder': 0.5, 'train': 0.16666666666666666, 'track': 0.2, 'near': 0.3333333333333333, 'fence': 0.3333333333333333, 'an': 0.16666666666666666, 'elephant': 0.14285714285714285, 'large': 0.09090909090909091, 'trunk': 0.5, 'dirt': 0.3333333333333333, 'ground': 0.5, 'stuffed': 0.5, 'animal': 0.5, 'teddy': 0.25, 'bear': 0.2, 'it': 0.2, 'plate': 0.09090909090909091, 'food': 0.14285714285714285, 'meat,': 0.3333333333333333, 'broccoli': 0.3333333333333333, 'potatoes': 0.5, 'suit': 0.25, 'tie': 0.2, 'looking': 0.3333333333333333, 'his': 0.3333333333333333, 'cell': 0.3333333333333333, 'phone': 0.3333333333333333, 'motorcycle': 0.2, 'the': 0.09090909090909091, 'side': 0.25, 'road': 0.3333333333333333, 'walking': 0.14285714285714285, 'through': 0.16666666666666666, 'forest': 0.5, 'leaves': 0.5, 'black': 0.2, 'table': 0.14285714285714285, 'hot': 0.3333333333333333, 'dog': 0.125, 'bun': 0.5, 'remote': 0.3333333333333333, 'control': 0.3333333333333333, 'couch': 0.5, 'jetliner': 0.2, 'flying': 0.16666666666666666, 'cloudy': 0.5, 'sky': 0.25, 'speaking': 0.5, 'crowd': 0.5, 'rice': 0.5, 'vegetables': 0.5, 'person': 0.25, 'jumping': 0.3333333333333333, 'skateboard': 0.3333333333333333, 'ledge': 0.5, 'giraffe': 0.2, 'leaf': 0.5, \"it's\": 0.3333333333333333, 'head': 0.5, 'riding': 0.25, 'wave': 0.5, 'surfboard': 0.5, 'sur': 0.5, 'bedroom': 0.3333333333333333, 'bed,': 0.3333333333333333, 'chair,': 0.3333333333333333, 'window': 0.3333333333333333, 'room': 0.125, 'clock': 0.2, 'tower': 0.25, 'brick': 0.5, 'building': 0.2, 'sidewalk': 0.5, 'while': 0.5, 'walks': 0.5, 'by': 0.3333333333333333, 'three': 0.25, 'children': 0.5, 'laptop': 0.25, 'young': 0.5, 'girl': 0.5, 'skiing': 0.5, 'down': 0.2, 'snow': 0.3333333333333333, 'covered': 0.3333333333333333, 'slope': 0.5, 'small': 0.16666666666666666, 'boat': 0.3333333333333333, 'docked': 0.5, 'body': 0.5, 'water': 0.3333333333333333, 'computer': 0.25, 'mouse': 0.25, 'keyboard': 0.3333333333333333, 'women': 0.5, 'plates': 0.5, 'around': 0.5, 'outside': 0.5, 'bus': 0.3333333333333333, 'front': 0.2, 'living': 0.25, 'airport': 0.3333333333333333, 'tarmac': 0.5, 'baby': 0.25, 'laying': 0.1111111111111111, 'floor': 0.3333333333333333, 'stove': 0.5, 'child': 0.5, 'desk': 0.3333333333333333, 'laptop,': 0.5, 'monitor,': 0.5, 'row': 0.16666666666666666, 'motorcycles': 0.25, 'rack': 0.5, 'them': 0.5, 'fire': 0.25, 'hydrant': 0.5, 'white': 0.25, 'dress': 0.25, 'holding': 0.2, 'her': 0.5, 'hand': 0.3333333333333333, 'parking': 0.25, 'meter': 0.25, 'stripe': 0.5, 'market': 0.5, 'bunch': 0.5, 'fruit': 0.5, 'plane': 0.3333333333333333, 'cloud': 0.5, 'filled': 0.5, 'bed': 0.25, 'runway': 0.5, 'blue': 0.5, 'couch,': 0.5, 'television': 0.5, 'place': 0.5, 'cat': 0.08333333333333333, 'wearing': 0.3333333333333333, 'shirt': 0.5, 'petting': 0.5, 'street': 0.1111111111111111, 'couple': 0.5, 'bench': 0.5, 'background': 0.5, 'double': 0.3333333333333333, 'decker': 0.5, 'driving': 0.5, 'deck': 0.5, 'benches': 0.5, 'pier': 0.5, 'racket': 0.3333333333333333, 'high': 0.5, 'chair': 0.3333333333333333, 'eating': 0.3333333333333333, 'carrots': 0.5, 'sign': 0.2, 'pole': 0.3333333333333333, 'stop': 0.3333333333333333, 'graffiti': 0.5, 'sticker': 0.5, 'kitchen': 0.16666666666666666, 'stove,': 0.3333333333333333, 'sink,': 0.25, 'refrigerator': 0.3333333333333333, 'two': 0.25, 'cats': 0.5, 'middle': 0.5, 'pizza': 0.3333333333333333, 'cheese': 0.5, 'olives': 0.5, 'men': 0.5, 'flock': 0.2, 'birds': 0.2, 'over': 0.5, 'piece': 0.3333333333333333, 'cake': 0.3333333333333333, 'strawberries': 0.5, 'gir': 0.5, 'sill': 0.5, 'out': 0.5, 'race': 0.5, 'group': 0.5, 'hitting': 0.5, 'ketchup': 0.5, 'traffic': 0.5, 'light': 0.5, 'city': 0.5, 'progress': 0.5, 'batter': 0.5, 'up': 0.5, 't': 0.5, 'giant': 0.5, 'kite': 0.5, 'blanket': 0.5, 'red': 0.5, 'cupcake': 0.5, 'oven': 0.3333333333333333, 'counter': 0.5, 'vase': 0.25, 'flowers': 0.5, 'bottle': 0.5, 'bathroom': 0.2, 'toilet': 0.5, 'sink': 0.5, 'mirror,': 0.5, 'bath': 0.5, 'tub': 0.5, 'plant': 0.5, 'rug': 0.5, 'grassy': 0.3333333333333333, 'platform': 0.5, 'dishwasher': 0.5, 'table,': 0.5, 'cloth,': 0.3333333333333333, 'tv': 0.5, 'video': 0.5, 'meat': 0.5, 'doing': 0.5, 'trick': 0.5, 'sheep': 0.3333333333333333, 'gas': 0.5, 'station': 0.5, 'wooden': 0.5, 'post': 0.5}\n"
     ]
    }
   ],
   "source": [
    "encoding_dict = Counter() # Counter is a subclass of dictionary for counting hashable objects\n",
    "threshold = 0 # threshold for word frequency # TODO: find a good threshold\n",
    "\n",
    "update_encoding_dict(generated_captions, encoding_dict)\n",
    "\n",
    "print (encoding_dict)\n",
    "\n",
    "# Optionally, create a more compressed form based on frequency\n",
    "compressed_dict = {word: idx for idx, (word, freq) in enumerate(encoding_dict.items()) if freq > threshold}\n",
    "\n",
    "# Create the dictionary of entropy values from encoding_dict\n",
    "entropy_dict = {word: -np.log(encoding_dict[word] / sum(encoding_dict.values())) \n",
    "                for word in encoding_dict}\n",
    "\n",
    "print (entropy_dict)\n",
    "# print 1/elem for elem in encoding_dict.values()\n",
    "reciprocal_dict = {word: 1/(encoding_dict[word]+1) for word in encoding_dict}\n",
    "print (reciprocal_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, captions):\n",
    "        self.encodings = encodings\n",
    "        self.captions = captions\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.captions[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `dataset` is your dataset containing images and captions\n",
    "images = [data['image'] for data in dataset]\n",
    "caption_ids = generated_predicted_ids\n",
    "\n",
    "# Process images and captions\n",
    "inputs = feature_extractor(images=images, return_tensors=\"pt\") \n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = CaptionDataset(inputs, caption_ids)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, original_weight, rank):\n",
    "        super(LoRALayer, self).__init__()\n",
    "        self.original_weight = original_weight\n",
    "        self.rank = rank\n",
    "        self.device = original_weight.device\n",
    "        self.U = nn.Parameter(torch.Tensor(self.original_weight.size(0), self.rank)).to(self.device)\n",
    "        self.V = nn.Parameter(torch.Tensor(self.rank, self.original_weight.size(1))).to(self.device)\n",
    "        nn.init.xavier_uniform_(self.U)\n",
    "        nn.init.xavier_uniform_(self.V)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.original_weight + self.U @ self.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the first attention layer of the encoder\n",
    "# TODO: Try modifying other layers as well and check the results\n",
    "lora_layers = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    original_weight = model.encoder.encoder.layer[0].attention.output.dense.weight\n",
    "    lora_layer = LoRALayer(original_weight, rank=10).to(device).forward()  # Choose an appropriate rank\n",
    "    # assign the new layer to the model\n",
    "    model.encoder.encoder.layer[0].attention.output.dense.weight.copy_(lora_layer)\n",
    "    # add the layer of the model to the list of LoRA layers\n",
    "    lora_layers.append(model.encoder.encoder.layer[0].attention.output.dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_lora_param(param, lora_layer):\n",
    "    # check if the parameter is part of the LoRA layer\n",
    "    print (lora_layer.parameters())\n",
    "    print (\"nuj\")\n",
    "    print (param)\n",
    "    return param in lora_layer.parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add two extra dimensions to generated_logits\n",
    "generated_probs = F.softmax(generated_logits, dim=-1)\n",
    "generated_probs_expanded = generated_probs.unsqueeze(0).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy_elbo_difference (prob_differences, D):\n",
    "    sigma = 0.01\n",
    "    # reduce prob_differences to 4D from 5D by taking norm square along the last dimension\n",
    "    prob_differences = prob_differences.to(device)\n",
    "    prob_differences = torch.norm(prob_differences, dim=-1)\n",
    "    print (prob_differences.shape)\n",
    "    # do elementwise for prob_differences: suqare\n",
    "    prob_differences = prob_differences**2\n",
    "    # take sum of all elements of prob_differences, hence scalar, then divide by 2*sigma^2*D\n",
    "    return torch.sum(prob_differences) / (2*sigma**2*D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy_elbo_cross_entropy (prob_differences, D):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy (prob_differences, D):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(outputs, batch, encoding_dict, lora_layers, lambda_val=10, lora_lambda_val = 0.01):\n",
    "    # Sending all to GPU\n",
    "    outputs.logits = outputs.logits.to(device)\n",
    "    outputs.loss = outputs.loss.to(device)\n",
    "    \n",
    "    # Standard captioning loss\n",
    "    standard_loss = outputs.loss\n",
    "\n",
    "    # Additional compression loss\n",
    "    compression_loss = 0\n",
    "    # add two dimensions to output probs at 2 and 3\n",
    "    outputs_probs = F.softmax(outputs.logits, dim=-1)\n",
    "    outputs_probs_expanded = outputs_probs.squeeze(1).unsqueeze(2).unsqueeze(3)\n",
    "    prob_differences = generated_probs_expanded - outputs_probs_expanded\n",
    "    print (\"prob_differences.shape = \", outputs_probs.shape, generated_probs_expanded.shape, outputs_probs_expanded.shape, prob_differences.shape)\n",
    "    # calculate the compression loss\n",
    "    # find number of elements in generated_predicted_logits\n",
    "    D = generated_probs.numel()\n",
    "    compression_loss = lambda_val* calculate_entropy_elbo_difference (prob_differences, D)\n",
    "    \n",
    "\n",
    "    # Optionally, add a term for LoRA regularization if needed\n",
    "    lora_regularization = 0\n",
    "    # for param in model.parameters():\n",
    "    #     for lora_layer in lora_layers:\n",
    "    #         if is_lora_param(param, lora_layer):\n",
    "    #             lora_regularization += torch.norm(param)\n",
    "    print (standard_loss, compression_loss)\n",
    "\n",
    "    return standard_loss + compression_loss + lora_lambda_val * lora_regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipykernel_5613/3431795457.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_5613/3431795457.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.captions[idx])\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 134.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 14.48 GiB is free. Including non-PyTorch memory, this process has 7.50 GiB memory in use. Of the allocated memory 7.13 GiB is allocated by PyTorch, and 62.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m---> 20\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[26], line 14\u001b[0m, in \u001b[0;36mcustom_loss\u001b[0;34m(outputs, batch, encoding_dict, lora_layers, lambda_val, lora_lambda_val)\u001b[0m\n\u001b[1;32m     12\u001b[0m outputs_probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m outputs_probs_expanded \u001b[38;5;241m=\u001b[39m outputs_probs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m prob_differences \u001b[38;5;241m=\u001b[39m \u001b[43mgenerated_probs_expanded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutputs_probs_expanded\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob_differences.shape = \u001b[39m\u001b[38;5;124m\"\u001b[39m, outputs_probs\u001b[38;5;241m.\u001b[39mshape, generated_probs_expanded\u001b[38;5;241m.\u001b[39mshape, outputs_probs_expanded\u001b[38;5;241m.\u001b[39mshape, prob_differences\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# calculate the compression loss\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# find number of elements in generated_predicted_logits\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 134.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 14.48 GiB is free. Including non-PyTorch memory, this process has 7.50 GiB memory in use. Of the allocated memory 7.13 GiB is allocated by PyTorch, and 62.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Fine tuning using custom loss\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "lr = 1e-4\n",
    "num_epochs = 30\n",
    "\n",
    "optimizer = AdamW([param for param in model.parameters() if param.requires_grad], lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = custom_loss(outputs, batch, encoding_dict, lora_layers)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory to save the model if it doesn't exist\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "# save model checkpoint to models directory using current timestamp and date\n",
    "torch.save(model.state_dict(), f\"models/{time.strftime('%Y%m%d-%H%M%S')}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderModel(\n",
       "  (encoder): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (pooler): ViTPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load latest model checkpoint among all the saved models\n",
    "latest_model = torch.load(max(glob.glob('models/*.pth'), key=os.path.getctime))\n",
    "# load the model with the latest checkpoint\n",
    "model.load_state_dict(latest_model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate captions for the test dataset\n",
    "generated_captions_custom_model = []\n",
    "# Iterate over the dataset and generate captions\n",
    "for data in dataset:\n",
    "    image = data['image']\n",
    "    generated_logits, generated_predicted_ids, caption = generate_caption_with_logits(image)\n",
    "    generated_captions_custom_model.append(caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode compressed dictionary word using manual huffman encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace compressed_dict words occurring in the generated_captions_custom_model with their corresponding huffman encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare encoded generated_captions_custom_model + huffman encoding dictionary information with the original generated_captions to calculate compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a green truck parked next to a curb  WAIT a green truck next to a curb next to a\n",
      "a man is walking down the street with a skate WAIT a man walking down the street with a a a\n"
     ]
    }
   ],
   "source": [
    "# print generated_captions and generated_captions_custom_model elementwise to compare the results\n",
    "for i in range(len(generated_captions)):\n",
    "    print (generated_captions[i], \"WAIT\", generated_captions_custom_model[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
