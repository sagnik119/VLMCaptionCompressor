{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing manual compression of image captions on stale (offline) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bert==2.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: bitsandbytes==0.42.0 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 2)) (0.42.0)\n",
      "Requirement already satisfied: datasets==2.15.0 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 3)) (2.15.0)\n",
      "Requirement already satisfied: fiftyone==0.23.4 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 4)) (0.23.4)\n",
      "Requirement already satisfied: glob2==0.7 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 5)) (0.7)\n",
      "Requirement already satisfied: gradio==4.15.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 6)) (4.15.0)\n",
      "Requirement already satisfied: gradio_client==0.8.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 7)) (0.8.1)\n",
      "Requirement already satisfied: ipykernel==6.27.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 8)) (6.27.1)\n",
      "Requirement already satisfied: ipython==8.12.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 9)) (8.12.3)\n",
      "Requirement already satisfied: llava==0.0.1.dev0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 10)) (0.0.1.dev0)\n",
      "Requirement already satisfied: pandas==2.1.4 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 11)) (2.1.4)\n",
      "Requirement already satisfied: sacrebleu==1.5.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: safetensors==0.4.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 13)) (0.4.1)\n",
      "Requirement already satisfied: torch==2.1.1 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 14)) (2.1.1)\n",
      "Requirement already satisfied: torchaudio==2.1.1 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 15)) (2.1.1)\n",
      "Requirement already satisfied: torchvision==0.16.1 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 16)) (0.16.1)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 17)) (4.66.1)\n",
      "Requirement already satisfied: transformers==4.36.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 18)) (4.36.0)\n",
      "Requirement already satisfied: wandb==0.16.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 19)) (0.16.2)\n",
      "Requirement already satisfied: erlastic in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from bert==2.2.0->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: scipy in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 2)) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (1.26.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Library/Python/3.9/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0->-r requirements.txt (line 3)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Python/3.9/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (0.19.4)\n",
      "Requirement already satisfied: packaging in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from datasets==2.15.0->-r requirements.txt (line 3)) (6.0.1)\n",
      "Requirement already satisfied: aiofiles in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (23.2.1)\n",
      "Requirement already satisfied: argcomplete in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (3.2.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (4.12.3)\n",
      "Requirement already satisfied: boto3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.34.29)\n",
      "Requirement already satisfied: cachetools in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (5.3.2)\n",
      "Requirement already satisfied: dacite<1.8.0,>=1.6.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: Deprecated in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.2.14)\n",
      "Requirement already satisfied: ftfy in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (6.1.3)\n",
      "Requirement already satisfied: humanize in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (4.9.0)\n",
      "Requirement already satisfied: hypercorn>=0.13.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: Jinja2>=3 in /Library/Python/3.9/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (3.1.2)\n",
      "Requirement already satisfied: kaleido!=0.2.1.post1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.2.1)\n",
      "Requirement already satisfied: matplotlib in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (3.8.2)\n",
      "Requirement already satisfied: mongoengine==0.24.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.24.2)\n",
      "Requirement already satisfied: motor>=2.5 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: Pillow>=6.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (10.1.0)\n",
      "Requirement already satisfied: plotly>=4.14 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (5.18.0)\n",
      "Requirement already satisfied: pprintpp in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: psutil in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (5.9.6)\n",
      "Requirement already satisfied: pymongo>=3.12 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (4.6.1)\n",
      "Requirement already satisfied: pytz in /Library/Python/3.9/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (2023.3.post1)\n",
      "Requirement already satisfied: regex in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (2023.10.3)\n",
      "Requirement already satisfied: retrying in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: scikit-image in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.22.0)\n",
      "Requirement already satisfied: setuptools in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (58.0.4)\n",
      "Requirement already satisfied: sseclient-py<2,>=1.7.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: sse-starlette<1,>=0.10.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.10.3)\n",
      "Requirement already satisfied: starlette>=0.24.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.27.0)\n",
      "Requirement already satisfied: strawberry-graphql==0.138.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.138.1)\n",
      "Requirement already satisfied: tabulate in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: xmltodict in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.13.0)\n",
      "Requirement already satisfied: universal-analytics-python3<2,>=1.0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: fiftyone-brain<0.17,>=0.16.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: fiftyone-db<2.0,>=0.4 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: voxel51-eta<0.13,>=0.12.4 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (0.12.4)\n",
      "Requirement already satisfied: opencv-python-headless in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from fiftyone==0.23.4->-r requirements.txt (line 4)) (4.9.0.80)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (5.2.0)\n",
      "Requirement already satisfied: fastapi in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.105.0)\n",
      "Requirement already satisfied: ffmpy in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.3.1)\n",
      "Requirement already satisfied: httpx in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.24.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (6.1.1)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Library/Python/3.9/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (2.1.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (3.9.12)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (2.5.3)\n",
      "Requirement already satisfied: pydub in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.0.6)\n",
      "Requirement already satisfied: ruff>=0.1.7 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.1.14)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (4.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio==4.15.0->-r requirements.txt (line 6)) (0.22.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gradio_client==0.8.1->-r requirements.txt (line 7)) (11.0.3)\n",
      "Requirement already satisfied: appnope in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (0.1.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (1.5.8)\n",
      "Requirement already satisfied: pyzmq>=20 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.27.1->-r requirements.txt (line 8)) (5.14.0)\n",
      "Requirement already satisfied: backcall in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (0.19.1)\n",
      "Requirement already satisfied: pickleshare in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from ipython==8.12.3->-r requirements.txt (line 9)) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Python/3.9/site-packages (from pandas==2.1.4->-r requirements.txt (line 11)) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Python/3.9/site-packages (from pandas==2.1.4->-r requirements.txt (line 11)) (2023.3)\n",
      "Requirement already satisfied: portalocker in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from sacrebleu==1.5.0->-r requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: filelock in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from torch==2.1.1->-r requirements.txt (line 14)) (3.13.1)\n",
      "Requirement already satisfied: sympy in /Library/Python/3.9/site-packages (from torch==2.1.1->-r requirements.txt (line 14)) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Python/3.9/site-packages (from torch==2.1.1->-r requirements.txt (line 14)) (3.2.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from transformers==4.36.0->-r requirements.txt (line 18)) (0.15.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (3.1.41)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (1.39.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (1.3.3)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from wandb==0.16.2->-r requirements.txt (line 19)) (4.25.2)\n",
      "Requirement already satisfied: graphql-core<3.3.0,>=3.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from strawberry-graphql==0.138.1->fiftyone==0.23.4->-r requirements.txt (line 4)) (3.2.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from altair<6.0,>=4.2.0->gradio==4.15.0->-r requirements.txt (line 6)) (4.21.1)\n",
      "Requirement already satisfied: toolz in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from altair<6.0,>=4.2.0->gradio==4.15.0->-r requirements.txt (line 6)) (0.12.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb==0.16.2->-r requirements.txt (line 19)) (1.15.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Library/Python/3.9/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.16.2->-r requirements.txt (line 19)) (4.0.11)\n",
      "Requirement already satisfied: h11 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: h2>=3.1.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (4.1.0)\n",
      "Requirement already satisfied: priority in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: taskgroup in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.0.0a4)\n",
      "Requirement already satisfied: tomli in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.0.1)\n",
      "Requirement already satisfied: wsproto>=0.14.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from importlib-resources<7.0,>=1.3->gradio==4.15.0->-r requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jedi>=0.16->ipython==8.12.3->-r requirements.txt (line 9)) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel==6.27.1->-r requirements.txt (line 8)) (7.0.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.27.1->-r requirements.txt (line 8)) (4.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from matplotlib->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from matplotlib->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from matplotlib->fiftyone==0.23.4->-r requirements.txt (line 4)) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from matplotlib->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from matplotlib->fiftyone==0.23.4->-r requirements.txt (line 4)) (3.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3->ipython==8.12.3->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from plotly>=4.14->fiftyone==0.23.4->-r requirements.txt (line 4)) (8.2.3)\n",
      "Requirement already satisfied: wcwidth in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython==8.12.3->-r requirements.txt (line 9)) (0.2.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.0->gradio==4.15.0->-r requirements.txt (line 6)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.0->gradio==4.15.0->-r requirements.txt (line 6)) (2.14.6)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from pymongo>=3.12->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets==2.15.0->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets==2.15.0->-r requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets==2.15.0->-r requirements.txt (line 3)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets==2.15.0->-r requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from starlette>=0.24.0->fiftyone==0.23.4->-r requirements.txt (line 4)) (3.7.1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (13.7.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from httpx->gradio==4.15.0->-r requirements.txt (line 6)) (0.17.3)\n",
      "Requirement already satisfied: sniffio in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from httpx->gradio==4.15.0->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: future in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.18.2)\n",
      "Requirement already satisfied: jsonlines in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: py7zr in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.20.8)\n",
      "Requirement already satisfied: rarfile in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (4.1)\n",
      "Requirement already satisfied: sortedcontainers in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: tzlocal in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (5.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.5)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.29 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from boto3->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.34.29)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from boto3->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from boto3->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from Deprecated->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from scikit-image->fiftyone==0.23.4->-r requirements.txt (line 4)) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from scikit-image->fiftyone==0.23.4->-r requirements.txt (line 4)) (2023.12.9)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from scikit-image->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from scikit-learn->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from scikit-learn->fiftyone==0.23.4->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython==8.12.3->-r requirements.txt (line 9)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython==8.12.3->-r requirements.txt (line 9)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython==8.12.3->-r requirements.txt (line 9)) (0.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Python/3.9/site-packages (from sympy->torch==2.1.1->-r requirements.txt (line 14)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.16.2->-r requirements.txt (line 19)) (5.0.1)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone==0.23.4->-r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.15.0->-r requirements.txt (line 6)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.15.0->-r requirements.txt (line 6)) (0.32.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.15.0->-r requirements.txt (line 6)) (0.17.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: texttable in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (3.20.0)\n",
      "Requirement already satisfied: pyzstd>=0.15.9 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.15.9)\n",
      "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.0.2)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (0.2.3)\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.4->fiftyone==0.23.4->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sagnik/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.15.0->-r requirements.txt (line 6)) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sagnik/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer, BitsAndBytesConfig, AutoProcessor, LlavaForConditionalGeneration\n",
    "from transformers import AdamW\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from collections import Counter\n",
    "import fiftyone\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "\n",
    "# uncommon features  - events of interest\n",
    "# loss less compression -  sudden more bits indicates anomaly can be flagged, alerts when anomaly detected - may shift to lossy video streaming\n",
    "# lossy compression of noisy data varying distortion rate - accuracy is increasing\n",
    "# video to video lossy reconstruction possibility\n",
    "# image frame to image frame on a need basis - human satisfaction metric, GPT based comparison, RLHF based comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sagnik/Library/Python/3.9/lib/python/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model and its components\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "# # Loading the above for LlavVA\n",
    "# model_llava = LlavaForConditionalGeneration.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "# processor_llava = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 81434/81434 [00:00<00:00, 1036333.54it/s]\n",
      "Resolving data files: 100%|██████████| 81434/81434 [00:00<00:00, 1101813.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset (for example, a subset of the COCO dataset)\n",
    "# TODO: Potential datasets with repetitive nature that can be used: MS COCO, Flickr30k, Visual Genome, SBU Captions - get correlated datasets from Nikil\n",
    "\n",
    "# load small part of the coco dataset from all the .jpg images in datasets/mscoco/test2015\n",
    "dataset_dict = load_dataset(\"datasets/mscoco/test2015/\", split=\"test[:100]\")\n",
    "dataset_finetune = load_dataset(\"datasets/mscoco/test2015/\", split=\"test[:200]\")\n",
    "# TODO: Determine if having same images for dictionary and fine tuning helps, or overlap or completely different images help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use different values of max_length and try out results\n",
    "\n",
    "def generate_caption_with_logits(image, max_length=15):\n",
    "    # define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Prepare the inputs\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n",
    "    pixel_values = inputs.pixel_values\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Perform a forward pass to get the logits\n",
    "        encoder_outputs = model.encoder(pixel_values=pixel_values)\n",
    "        encoder_hidden_states = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Prepare decoder input_ids. Typically, you start with the start-of-sentence token\n",
    "        decoder_input_ids = torch.tensor([tokenizer.bos_token_id]).unsqueeze(0).to(encoder_hidden_states.device)\n",
    "        decoder_attention_mask = torch.ones_like(decoder_input_ids)\n",
    "        \n",
    "        # Initialize an empty tensor for logits (for simplicity, accumulating logits for each step)\n",
    "        logits_list = []\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            decoder_outputs = model.decoder(input_ids=decoder_input_ids,\n",
    "                                            attention_mask=decoder_attention_mask,\n",
    "                                            encoder_hidden_states=encoder_hidden_states)\n",
    "            logits = decoder_outputs.logits[:, -1, :]  # Get the logits for the last token generated\n",
    "            logits_list.append(logits)\n",
    "            \n",
    "            predicted_id = torch.argmax(logits, dim=-1).unsqueeze(-1)\n",
    "            # Check if EOS token is generated\n",
    "            if predicted_id[0, 0] == tokenizer.eos_token_id:\n",
    "                print (\"EOS has been generated\")\n",
    "                # break # since model.generate() does this automatically\n",
    "            \n",
    "            # Append predicted token ID to decoder_input_ids for generating next token\n",
    "            decoder_input_ids = torch.cat([decoder_input_ids, predicted_id], dim=-1)\n",
    "            decoder_attention_mask = torch.cat([decoder_attention_mask, torch.ones_like(predicted_id).to(device)], dim=-1)\n",
    "            \n",
    "        # Concatenate logits from each step to get the final logits tensor\n",
    "        # make all elements of logits_list 3D by adding a dimension in the middle\n",
    "        logits_list = [logits.unsqueeze(1) for logits in logits_list]\n",
    "        logits = torch.cat(logits_list, dim=1)\n",
    "        # add logic to repeat the remaining number of (127-i) tokens with EOS token logits (simply repeat the last token logits) to make it length 128\n",
    "\n",
    "        # Decode the generated token IDs to get the caption\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        caption = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "    return logits, predicted_ids, caption\n",
    "\n",
    "# Example usage\n",
    "# image: A PIL image or a tensor representing your input image\n",
    "# logits, predicted_ids, caption = generate_caption_with_logits(image, model, feature_extractor, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "torch.Size([100, 15, 50257])\n",
      "torch.Size([287])\n",
      "torch.Size([287, 50257])\n"
     ]
    }
   ],
   "source": [
    "def generate_captions_logits_ids_from_dataset(dataset_dict):\n",
    "    # Iterate over the dataset and generate captions\n",
    "    generated_captions = []\n",
    "    generated_logits = []\n",
    "    generated_predicted_ids = []\n",
    "\n",
    "    for data in dataset_dict:\n",
    "        image = data['image']\n",
    "        logits, predicted_ids, caption = generate_caption_with_logits(image)\n",
    "        generated_captions.append(caption)\n",
    "        generated_logits.append(logits)\n",
    "        generated_predicted_ids.append(predicted_ids)\n",
    "\n",
    "    # concatenate generated logits along first dimension to make 3D tensor\n",
    "    generated_logits = torch.cat(generated_logits, dim=0)\n",
    "    print (generated_logits.shape)\n",
    "\n",
    "    # concatenate generated predicted_ids along first dimension to make 2D tensor\n",
    "    generated_predicted_ids = torch.cat(generated_predicted_ids, dim=0)\n",
    "\n",
    "    # form new tensor of size unique tokens * vocab size : each row is the means of logits of all tokens with that id\\n\",\n",
    "    # find unique elements in generated_predicted_ids, result should be a 1D tensor\\n\",\n",
    "    unique_tokens = torch.unique(generated_predicted_ids)\n",
    "    # store torch tensor of the number of times each unique token appears in generated_predicted_ids -  remember generated_predicted_ids is a 2D tensor\n",
    "    unique_token_counts = torch.zeros(unique_tokens.shape[0]).to(device)\n",
    "    for i, token in enumerate(unique_tokens):\n",
    "        unique_token_counts[i] = torch.sum(generated_predicted_ids == token)\n",
    "    unique_token_probs = unique_token_counts / torch.sum(unique_token_counts)\n",
    "    print (unique_token_counts.shape)\n",
    "    # find the mean of logits for each unique token\n",
    "    mean_logits = torch.zeros(unique_tokens.shape[0], generated_logits.shape[2]).to(device)\n",
    "    for i, token in enumerate(unique_tokens):\n",
    "        mean_logits[i] = torch.mean(generated_logits[generated_predicted_ids == token], dim=0)\n",
    "    print (mean_logits.shape)\n",
    "    return generated_captions, generated_logits, generated_predicted_ids, unique_tokens, unique_token_probs, unique_token_counts, mean_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a green truck parked next to a curb a green truck parked next',\n",
       " 'a man is walking down the street with a skateboard a man',\n",
       " 'a baseball player swinging a bat at a ball a baseball player swinging',\n",
       " 'a cow is standing in a field of grass a cow is standing',\n",
       " 'a black dog sitting in the back of a truck a black dog',\n",
       " 'a man wearing a bow tie and glasses a man wearing a bow',\n",
       " 'a dining room table with a large bowl of food a large kitchen',\n",
       " 'a man standing next to a wall with a bunch of guitars a',\n",
       " 'a man is playing tennis on a clay court a man is playing',\n",
       " 'a man and a woman playing a game of frisbee a',\n",
       " 'a woman and a man are drinking wine people are sitting at a',\n",
       " 'people are standing around a table people are drinking wine people',\n",
       " 'a zebra standing in a fenced in area a zebra',\n",
       " 'two dogs are looking at each other in a room a dog is',\n",
       " 'a horse grazing in a field with a tree a horse grazing in',\n",
       " 'a bird perched on top of a bird feeder a bird sitting',\n",
       " 'a train on a track near a fence a train on a track',\n",
       " 'a plate of food with a fish and vegetables a person sitting at',\n",
       " 'an elephant with a large trunk standing on a dirt ground a elephant',\n",
       " 'people are watching a television show people are watching a movie ',\n",
       " 'a woman is cooking food in a kitchen a woman is cooking food',\n",
       " 'a stuffed animal with a teddy bear on it a teddy',\n",
       " 'a plate of food with meat, broccoli and potatoes a plate of',\n",
       " 'a man in a suit and tie looking at his cell phone a',\n",
       " 'a man holding a tennis racquet on a tennis court a man',\n",
       " 'a man sitting on a couch with a laptop a man sitting on',\n",
       " 'a motorcycle parked on the side of a road a motorcycle is parked',\n",
       " 'a bear walking through a forest with leaves a black bear standing in',\n",
       " 'a truck with a bed and a fence a truck with a bed',\n",
       " 'a plate of food on a table a hot dog on a bun',\n",
       " 'a man wearing a hat and a red scarf a man with a',\n",
       " 'a herd of sheep grazing in a field a herd of sheep standing',\n",
       " 'a remote control sitting on top of a couch a remote control sitting',\n",
       " 'a large jetliner flying through a cloudy sky a large jetliner',\n",
       " 'a man in a suit and tie speaking to a crowd a man',\n",
       " 'a plate of food with meat, rice and vegetables a plate of',\n",
       " 'a person jumping a skateboard on a ledge a person jumping a',\n",
       " 'a man is playing tennis on a court a man is playing tennis',\n",
       " \"a giraffe standing next to a tree with a leaf on it's head\",\n",
       " 'a woman standing on a beach holding an umbrella people are walking on',\n",
       " 'a man riding a wave on top of a surfboard a sur',\n",
       " 'a teddy bear sitting on a chair in a room a t',\n",
       " 'a man riding a bike down a street a man riding a motorcycle',\n",
       " 'a bedroom with a bed, chair, and a window a room',\n",
       " \"a clock tower with a clock on it's side a clock tower\",\n",
       " 'a fire truck is parked at a stop light a fire truck is',\n",
       " 'a collection of items including a purse, a bag, a pair of shoes',\n",
       " 'a large brick building with a clock tower a large building with a',\n",
       " 'a woman is sitting on the sidewalk while a man walks by people',\n",
       " 'a tray of food with a spoon and a bowl of food a',\n",
       " 'a man holding a tray of donuts a man holding a box',\n",
       " 'three children sitting at a table with a laptop people sitting at a',\n",
       " 'a man hitting a tennis ball with a tennis racquet a man',\n",
       " 'a cat laying on a couch next to a pillow a cat laying',\n",
       " 'a woman in a pink dress playing a game with a nintendo wii',\n",
       " 'a young girl skiing down a snow covered slope a person on a',\n",
       " 'a small boat docked in a body of water a small boat',\n",
       " 'a computer mouse sitting on top of a keyboard a computer mouse sitting',\n",
       " 'a toilet sitting in a dirty area next to a building a toilet',\n",
       " 'a man swinging a tennis racket at a ball a man is playing',\n",
       " 'a man in a black shirt is working on a laptop a man',\n",
       " 'a large building with a clock on it a city street with a',\n",
       " 'three women sitting at a table with plates of food people sitting around',\n",
       " 'people are standing outside of a bus people are standing in front of',\n",
       " 'a man and a woman are standing in a living room a man',\n",
       " 'a street sign on a pole in front of a house a street',\n",
       " 'a birthday cake with a train on it a cake with a man',\n",
       " 'a large jetliner sitting on top of an airport tarmac a',\n",
       " 'a person para sailing on a body of water a person para sailing',\n",
       " 'a baby laying on the floor next to a stove a child is',\n",
       " 'cows standing in a field a herd of cattle standing in a',\n",
       " 'a man sitting at a table with a pizza a man is eating',\n",
       " 'a fire hydrant in the middle of a grassy field a',\n",
       " 'a police officer on a horse a man in a uniform is on',\n",
       " 'a desk with a laptop, monitor, keyboard and mouse a laptop',\n",
       " 'two zebras standing in a field of tall grass two ze',\n",
       " 'a zebra standing in a fenced in area a zebra',\n",
       " 'a man riding a skateboard on top of a cement bowl a',\n",
       " 'a row of parked motorcycles with a rack of them a row of',\n",
       " 'a fire hydrant is covered in snow by a tree a fire',\n",
       " 'a woman in a white dress playing tennis a woman in a white',\n",
       " 'a woman holding a cell phone in her hand a woman holding a',\n",
       " 'a cat laying on top of a laptop computer a cat laying on',\n",
       " 'a tree filled with lots of fruit and leaves a tree filled with',\n",
       " 'a bear in a cage looking at the camera a bear in a',\n",
       " 'a parking meter with a black stripe on it a parking meter with',\n",
       " 'a train is parked on the tracks in a station a train is',\n",
       " 'a woman sitting in a market with a bunch of fruit a woman',\n",
       " 'two men are riding motorcycles on a road two people are sitting on',\n",
       " 'a plane flying through a cloud filled sky a plane flying through a',\n",
       " 'two men are playing tennis on a court a man is holding a',\n",
       " 'a woman standing on a bed with a dress on a woman is',\n",
       " 'a large jetliner sitting on top of an airport runway a blue',\n",
       " 'a living room with a couch, television and a fire place a',\n",
       " 'a cat wearing a tie and a shirt a cat wearing a tie',\n",
       " 'a woman in a black dress is petting a black dog a',\n",
       " 'people walking down a street people walking down a street people',\n",
       " 'a traffic light sitting on the side of a road a street light',\n",
       " \"a large elephant with people riding on it's back people riding on\",\n",
       " 'a couple sitting on a bench with a sky background a man and']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_captions_dict, generated_logits_dict, generated_predicted_ids_dict, unique_tokens_dict, unique_token_probs_dict, unique_token_counts_dict, mean_logits_dict = generate_captions_logits_ids_from_dataset(dataset_dict)\n",
    "generated_captions_finetune, generated_logits_finetune, generated_predicted_ids_finetune, unique_tokens_finetune, unique_token_probs_finetune, unique_token_counts_finetune, mean_logits_finetune = generate_captions_logits_ids_from_dataset(dataset_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_encoding_dict(captions, encoding_dict):\n",
    "    for caption in captions:\n",
    "        words = caption.split() # splitting the caption into words - pretty bad strategy since we are currently splitting into tokens\n",
    "        encoding_dict.update(words) # purpose of update is to add the words to the dictionary if they don't exist\n",
    "    return encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'a': 329, 'on': 49, 'of': 42, 'man': 41, 'with': 40, 'in': 36, 'is': 25, 'sitting': 24, 'standing': 18, 'and': 18, 'people': 18, 'woman': 17, 'are': 14, 'at': 12, 'large': 11, 'food': 10, 'tennis': 10, 'the': 9, 'playing': 9, 'street': 8, 'top': 8, 'truck': 7, 'parked': 7, 'next': 7, 'to': 7, 'black': 7, 'holding': 7, 'riding': 7, 'field': 6, 'room': 6, 'table': 6, 'two': 6, 'plate': 6, 'person': 6, 'bear': 6, 'fire': 6, 'cat': 6, 'walking': 5, 'down': 5, 'dog': 5, 'wearing': 5, 'tie': 5, 'tree': 5, 'train': 5, 'laptop': 5, 'clock': 5, 'laying': 5, 'court': 4, 'zebra': 4, 'an': 4, 'it': 4, 'through': 4, 'jetliner': 4, 'building': 4, 'dress': 4, 'skateboard': 3, 'swinging': 3, 'ball': 3, 'bowl': 3, 'area': 3, 'looking': 3, 'horse': 3, 'grazing': 3, 'bird': 3, 'elephant': 3, 'teddy': 3, 'couch': 3, 'motorcycle': 3, 'side': 3, 'road': 3, 'bed': 3, 'herd': 3, 'flying': 3, 'sky': 3, \"it's\": 3, 'tower': 3, 'light': 3, 'computer': 3, 'mouse': 3, 'filled': 3, 'green': 2, 'baseball': 2, 'player': 2, 'cow': 2, 'grass': 2, 'back': 2, 'bow': 2, 'kitchen': 2, 'bunch': 2, 'game': 2, 'drinking': 2, 'wine': 2, 'around': 2, 'fenced': 2, 'track': 2, 'fence': 2, 'vegetables': 2, 'watching': 2, 'television': 2, 'cooking': 2, 'meat,': 2, 'suit': 2, 'cell': 2, 'phone': 2, 'racquet': 2, 'leaves': 2, 'sheep': 2, 'remote': 2, 'control': 2, 'jumping': 2, 'by': 2, 'tray': 2, 'three': 2, 'snow': 2, 'covered': 2, 'small': 2, 'boat': 2, 'body': 2, 'water': 2, 'keyboard': 2, 'toilet': 2, 'shirt': 2, 'front': 2, 'living': 2, 'cake': 2, 'airport': 2, 'para': 2, 'sailing': 2, 'hydrant': 2, 'row': 2, 'motorcycles': 2, 'white': 2, 'fruit': 2, 'parking': 2, 'meter': 2, 'men': 2, 'plane': 2, 'curb': 1, 'bat': 1, 'glasses': 1, 'dining': 1, 'wall': 1, 'guitars': 1, 'clay': 1, 'frisbee': 1, 'dogs': 1, 'each': 1, 'other': 1, 'perched': 1, 'feeder': 1, 'near': 1, 'fish': 1, 'trunk': 1, 'dirt': 1, 'ground': 1, 'show': 1, 'movie': 1, 'stuffed': 1, 'animal': 1, 'broccoli': 1, 'potatoes': 1, 'his': 1, 'forest': 1, 'hot': 1, 'bun': 1, 'hat': 1, 'red': 1, 'scarf': 1, 'cloudy': 1, 'speaking': 1, 'crowd': 1, 'rice': 1, 'ledge': 1, 'giraffe': 1, 'leaf': 1, 'head': 1, 'beach': 1, 'umbrella': 1, 'wave': 1, 'surfboard': 1, 'sur': 1, 'chair': 1, 't': 1, 'bike': 1, 'bedroom': 1, 'bed,': 1, 'chair,': 1, 'window': 1, 'stop': 1, 'collection': 1, 'items': 1, 'including': 1, 'purse,': 1, 'bag,': 1, 'pair': 1, 'shoes': 1, 'brick': 1, 'sidewalk': 1, 'while': 1, 'walks': 1, 'spoon': 1, 'donuts': 1, 'box': 1, 'children': 1, 'hitting': 1, 'pillow': 1, 'pink': 1, 'nintendo': 1, 'wii': 1, 'young': 1, 'girl': 1, 'skiing': 1, 'slope': 1, 'docked': 1, 'dirty': 1, 'racket': 1, 'working': 1, 'city': 1, 'women': 1, 'plates': 1, 'outside': 1, 'bus': 1, 'sign': 1, 'pole': 1, 'house': 1, 'birthday': 1, 'tarmac': 1, 'baby': 1, 'floor': 1, 'stove': 1, 'child': 1, 'cows': 1, 'cattle': 1, 'pizza': 1, 'eating': 1, 'middle': 1, 'grassy': 1, 'police': 1, 'officer': 1, 'uniform': 1, 'desk': 1, 'laptop,': 1, 'monitor,': 1, 'zebras': 1, 'tall': 1, 'ze': 1, 'cement': 1, 'rack': 1, 'them': 1, 'her': 1, 'hand': 1, 'lots': 1, 'cage': 1, 'camera': 1, 'stripe': 1, 'tracks': 1, 'station': 1, 'market': 1, 'cloud': 1, 'runway': 1, 'blue': 1, 'couch,': 1, 'place': 1, 'petting': 1, 'traffic': 1, 'couple': 1, 'bench': 1, 'background': 1})\n",
      "{'a': 1.3372382041306965, 'green': 6.440148774336123, 'truck': 5.187385805840755, 'parked': 5.187385805840755, 'next': 5.187385805840755, 'to': 5.187385805840755, 'curb': 7.133295954896068, 'man': 3.4197238881917604, 'is': 3.9144201300278674, 'walking': 5.523858042461968, 'down': 5.523858042461968, 'the': 4.936071377559849, 'street': 5.053854413216232, 'with': 3.444416500782132, 'skateboard': 6.034683666227958, 'baseball': 6.440148774336123, 'player': 6.440148774336123, 'swinging': 6.034683666227958, 'bat': 7.133295954896068, 'at': 4.648389305108068, 'ball': 6.034683666227958, 'cow': 6.440148774336123, 'standing': 4.242924196999904, 'in': 3.5497770164399585, 'field': 5.341536485668013, 'of': 3.3956263366127, 'grass': 6.440148774336123, 'black': 5.187385805840755, 'dog': 5.523858042461968, 'sitting': 3.9552421245481226, 'back': 6.440148774336123, 'wearing': 5.523858042461968, 'bow': 6.440148774336123, 'tie': 5.523858042461968, 'and': 4.242924196999904, 'glasses': 7.133295954896068, 'dining': 7.133295954896068, 'room': 5.341536485668013, 'table': 5.341536485668013, 'large': 4.735400682097698, 'bowl': 6.034683666227958, 'food': 4.8307108619020225, 'kitchen': 6.440148774336123, 'wall': 7.133295954896068, 'bunch': 6.440148774336123, 'guitars': 7.133295954896068, 'playing': 4.936071377559849, 'tennis': 4.8307108619020225, 'on': 3.2414756567854415, 'clay': 7.133295954896068, 'court': 5.747001593776178, 'woman': 4.300082610839852, 'game': 6.440148774336123, 'frisbee': 7.133295954896068, 'are': 4.4942386252808095, 'drinking': 6.440148774336123, 'wine': 6.440148774336123, 'people': 4.242924196999904, 'around': 6.440148774336123, 'zebra': 5.747001593776178, 'fenced': 6.440148774336123, 'area': 6.034683666227958, 'two': 5.341536485668013, 'dogs': 7.133295954896068, 'looking': 6.034683666227958, 'each': 7.133295954896068, 'other': 7.133295954896068, 'horse': 6.034683666227958, 'grazing': 6.034683666227958, 'tree': 5.523858042461968, 'bird': 6.034683666227958, 'perched': 7.133295954896068, 'top': 5.053854413216232, 'feeder': 7.133295954896068, 'train': 5.523858042461968, 'track': 6.440148774336123, 'near': 7.133295954896068, 'fence': 6.440148774336123, 'plate': 5.341536485668013, 'fish': 7.133295954896068, 'vegetables': 6.440148774336123, 'person': 5.341536485668013, 'an': 5.747001593776178, 'elephant': 6.034683666227958, 'trunk': 7.133295954896068, 'dirt': 7.133295954896068, 'ground': 7.133295954896068, 'watching': 6.440148774336123, 'television': 6.440148774336123, 'show': 7.133295954896068, 'movie': 7.133295954896068, 'cooking': 6.440148774336123, 'stuffed': 7.133295954896068, 'animal': 7.133295954896068, 'teddy': 6.034683666227958, 'bear': 5.341536485668013, 'it': 5.747001593776178, 'meat,': 6.440148774336123, 'broccoli': 7.133295954896068, 'potatoes': 7.133295954896068, 'suit': 6.440148774336123, 'his': 7.133295954896068, 'cell': 6.440148774336123, 'phone': 6.440148774336123, 'holding': 5.187385805840755, 'racquet': 6.440148774336123, 'couch': 6.034683666227958, 'laptop': 5.523858042461968, 'motorcycle': 6.034683666227958, 'side': 6.034683666227958, 'road': 6.034683666227958, 'through': 5.747001593776178, 'forest': 7.133295954896068, 'leaves': 6.440148774336123, 'bed': 6.034683666227958, 'hot': 7.133295954896068, 'bun': 7.133295954896068, 'hat': 7.133295954896068, 'red': 7.133295954896068, 'scarf': 7.133295954896068, 'herd': 6.034683666227958, 'sheep': 6.440148774336123, 'remote': 6.440148774336123, 'control': 6.440148774336123, 'jetliner': 5.747001593776178, 'flying': 6.034683666227958, 'cloudy': 7.133295954896068, 'sky': 6.034683666227958, 'speaking': 7.133295954896068, 'crowd': 7.133295954896068, 'rice': 7.133295954896068, 'jumping': 6.440148774336123, 'ledge': 7.133295954896068, 'giraffe': 7.133295954896068, 'leaf': 7.133295954896068, \"it's\": 6.034683666227958, 'head': 7.133295954896068, 'beach': 7.133295954896068, 'umbrella': 7.133295954896068, 'riding': 5.187385805840755, 'wave': 7.133295954896068, 'surfboard': 7.133295954896068, 'sur': 7.133295954896068, 'chair': 7.133295954896068, 't': 7.133295954896068, 'bike': 7.133295954896068, 'bedroom': 7.133295954896068, 'bed,': 7.133295954896068, 'chair,': 7.133295954896068, 'window': 7.133295954896068, 'clock': 5.523858042461968, 'tower': 6.034683666227958, 'fire': 5.341536485668013, 'stop': 7.133295954896068, 'light': 6.034683666227958, 'collection': 7.133295954896068, 'items': 7.133295954896068, 'including': 7.133295954896068, 'purse,': 7.133295954896068, 'bag,': 7.133295954896068, 'pair': 7.133295954896068, 'shoes': 7.133295954896068, 'brick': 7.133295954896068, 'building': 5.747001593776178, 'sidewalk': 7.133295954896068, 'while': 7.133295954896068, 'walks': 7.133295954896068, 'by': 6.440148774336123, 'tray': 6.440148774336123, 'spoon': 7.133295954896068, 'donuts': 7.133295954896068, 'box': 7.133295954896068, 'three': 6.440148774336123, 'children': 7.133295954896068, 'hitting': 7.133295954896068, 'cat': 5.341536485668013, 'laying': 5.523858042461968, 'pillow': 7.133295954896068, 'pink': 7.133295954896068, 'dress': 5.747001593776178, 'nintendo': 7.133295954896068, 'wii': 7.133295954896068, 'young': 7.133295954896068, 'girl': 7.133295954896068, 'skiing': 7.133295954896068, 'snow': 6.440148774336123, 'covered': 6.440148774336123, 'slope': 7.133295954896068, 'small': 6.440148774336123, 'boat': 6.440148774336123, 'docked': 7.133295954896068, 'body': 6.440148774336123, 'water': 6.440148774336123, 'computer': 6.034683666227958, 'mouse': 6.034683666227958, 'keyboard': 6.440148774336123, 'toilet': 6.440148774336123, 'dirty': 7.133295954896068, 'racket': 7.133295954896068, 'shirt': 6.440148774336123, 'working': 7.133295954896068, 'city': 7.133295954896068, 'women': 7.133295954896068, 'plates': 7.133295954896068, 'outside': 7.133295954896068, 'bus': 7.133295954896068, 'front': 6.440148774336123, 'living': 6.440148774336123, 'sign': 7.133295954896068, 'pole': 7.133295954896068, 'house': 7.133295954896068, 'birthday': 7.133295954896068, 'cake': 6.440148774336123, 'airport': 6.440148774336123, 'tarmac': 7.133295954896068, 'para': 6.440148774336123, 'sailing': 6.440148774336123, 'baby': 7.133295954896068, 'floor': 7.133295954896068, 'stove': 7.133295954896068, 'child': 7.133295954896068, 'cows': 7.133295954896068, 'cattle': 7.133295954896068, 'pizza': 7.133295954896068, 'eating': 7.133295954896068, 'hydrant': 6.440148774336123, 'middle': 7.133295954896068, 'grassy': 7.133295954896068, 'police': 7.133295954896068, 'officer': 7.133295954896068, 'uniform': 7.133295954896068, 'desk': 7.133295954896068, 'laptop,': 7.133295954896068, 'monitor,': 7.133295954896068, 'zebras': 7.133295954896068, 'tall': 7.133295954896068, 'ze': 7.133295954896068, 'cement': 7.133295954896068, 'row': 6.440148774336123, 'motorcycles': 6.440148774336123, 'rack': 7.133295954896068, 'them': 7.133295954896068, 'white': 6.440148774336123, 'her': 7.133295954896068, 'hand': 7.133295954896068, 'filled': 6.034683666227958, 'lots': 7.133295954896068, 'fruit': 6.440148774336123, 'cage': 7.133295954896068, 'camera': 7.133295954896068, 'parking': 6.440148774336123, 'meter': 6.440148774336123, 'stripe': 7.133295954896068, 'tracks': 7.133295954896068, 'station': 7.133295954896068, 'market': 7.133295954896068, 'men': 6.440148774336123, 'plane': 6.440148774336123, 'cloud': 7.133295954896068, 'runway': 7.133295954896068, 'blue': 7.133295954896068, 'couch,': 7.133295954896068, 'place': 7.133295954896068, 'petting': 7.133295954896068, 'traffic': 7.133295954896068, 'couple': 7.133295954896068, 'bench': 7.133295954896068, 'background': 7.133295954896068}\n",
      "{'a': 0.0030303030303030303, 'green': 0.3333333333333333, 'truck': 0.125, 'parked': 0.125, 'next': 0.125, 'to': 0.125, 'curb': 0.5, 'man': 0.023809523809523808, 'is': 0.038461538461538464, 'walking': 0.16666666666666666, 'down': 0.16666666666666666, 'the': 0.1, 'street': 0.1111111111111111, 'with': 0.024390243902439025, 'skateboard': 0.25, 'baseball': 0.3333333333333333, 'player': 0.3333333333333333, 'swinging': 0.25, 'bat': 0.5, 'at': 0.07692307692307693, 'ball': 0.25, 'cow': 0.3333333333333333, 'standing': 0.05263157894736842, 'in': 0.02702702702702703, 'field': 0.14285714285714285, 'of': 0.023255813953488372, 'grass': 0.3333333333333333, 'black': 0.125, 'dog': 0.16666666666666666, 'sitting': 0.04, 'back': 0.3333333333333333, 'wearing': 0.16666666666666666, 'bow': 0.3333333333333333, 'tie': 0.16666666666666666, 'and': 0.05263157894736842, 'glasses': 0.5, 'dining': 0.5, 'room': 0.14285714285714285, 'table': 0.14285714285714285, 'large': 0.08333333333333333, 'bowl': 0.25, 'food': 0.09090909090909091, 'kitchen': 0.3333333333333333, 'wall': 0.5, 'bunch': 0.3333333333333333, 'guitars': 0.5, 'playing': 0.1, 'tennis': 0.09090909090909091, 'on': 0.02, 'clay': 0.5, 'court': 0.2, 'woman': 0.05555555555555555, 'game': 0.3333333333333333, 'frisbee': 0.5, 'are': 0.06666666666666667, 'drinking': 0.3333333333333333, 'wine': 0.3333333333333333, 'people': 0.05263157894736842, 'around': 0.3333333333333333, 'zebra': 0.2, 'fenced': 0.3333333333333333, 'area': 0.25, 'two': 0.14285714285714285, 'dogs': 0.5, 'looking': 0.25, 'each': 0.5, 'other': 0.5, 'horse': 0.25, 'grazing': 0.25, 'tree': 0.16666666666666666, 'bird': 0.25, 'perched': 0.5, 'top': 0.1111111111111111, 'feeder': 0.5, 'train': 0.16666666666666666, 'track': 0.3333333333333333, 'near': 0.5, 'fence': 0.3333333333333333, 'plate': 0.14285714285714285, 'fish': 0.5, 'vegetables': 0.3333333333333333, 'person': 0.14285714285714285, 'an': 0.2, 'elephant': 0.25, 'trunk': 0.5, 'dirt': 0.5, 'ground': 0.5, 'watching': 0.3333333333333333, 'television': 0.3333333333333333, 'show': 0.5, 'movie': 0.5, 'cooking': 0.3333333333333333, 'stuffed': 0.5, 'animal': 0.5, 'teddy': 0.25, 'bear': 0.14285714285714285, 'it': 0.2, 'meat,': 0.3333333333333333, 'broccoli': 0.5, 'potatoes': 0.5, 'suit': 0.3333333333333333, 'his': 0.5, 'cell': 0.3333333333333333, 'phone': 0.3333333333333333, 'holding': 0.125, 'racquet': 0.3333333333333333, 'couch': 0.25, 'laptop': 0.16666666666666666, 'motorcycle': 0.25, 'side': 0.25, 'road': 0.25, 'through': 0.2, 'forest': 0.5, 'leaves': 0.3333333333333333, 'bed': 0.25, 'hot': 0.5, 'bun': 0.5, 'hat': 0.5, 'red': 0.5, 'scarf': 0.5, 'herd': 0.25, 'sheep': 0.3333333333333333, 'remote': 0.3333333333333333, 'control': 0.3333333333333333, 'jetliner': 0.2, 'flying': 0.25, 'cloudy': 0.5, 'sky': 0.25, 'speaking': 0.5, 'crowd': 0.5, 'rice': 0.5, 'jumping': 0.3333333333333333, 'ledge': 0.5, 'giraffe': 0.5, 'leaf': 0.5, \"it's\": 0.25, 'head': 0.5, 'beach': 0.5, 'umbrella': 0.5, 'riding': 0.125, 'wave': 0.5, 'surfboard': 0.5, 'sur': 0.5, 'chair': 0.5, 't': 0.5, 'bike': 0.5, 'bedroom': 0.5, 'bed,': 0.5, 'chair,': 0.5, 'window': 0.5, 'clock': 0.16666666666666666, 'tower': 0.25, 'fire': 0.14285714285714285, 'stop': 0.5, 'light': 0.25, 'collection': 0.5, 'items': 0.5, 'including': 0.5, 'purse,': 0.5, 'bag,': 0.5, 'pair': 0.5, 'shoes': 0.5, 'brick': 0.5, 'building': 0.2, 'sidewalk': 0.5, 'while': 0.5, 'walks': 0.5, 'by': 0.3333333333333333, 'tray': 0.3333333333333333, 'spoon': 0.5, 'donuts': 0.5, 'box': 0.5, 'three': 0.3333333333333333, 'children': 0.5, 'hitting': 0.5, 'cat': 0.14285714285714285, 'laying': 0.16666666666666666, 'pillow': 0.5, 'pink': 0.5, 'dress': 0.2, 'nintendo': 0.5, 'wii': 0.5, 'young': 0.5, 'girl': 0.5, 'skiing': 0.5, 'snow': 0.3333333333333333, 'covered': 0.3333333333333333, 'slope': 0.5, 'small': 0.3333333333333333, 'boat': 0.3333333333333333, 'docked': 0.5, 'body': 0.3333333333333333, 'water': 0.3333333333333333, 'computer': 0.25, 'mouse': 0.25, 'keyboard': 0.3333333333333333, 'toilet': 0.3333333333333333, 'dirty': 0.5, 'racket': 0.5, 'shirt': 0.3333333333333333, 'working': 0.5, 'city': 0.5, 'women': 0.5, 'plates': 0.5, 'outside': 0.5, 'bus': 0.5, 'front': 0.3333333333333333, 'living': 0.3333333333333333, 'sign': 0.5, 'pole': 0.5, 'house': 0.5, 'birthday': 0.5, 'cake': 0.3333333333333333, 'airport': 0.3333333333333333, 'tarmac': 0.5, 'para': 0.3333333333333333, 'sailing': 0.3333333333333333, 'baby': 0.5, 'floor': 0.5, 'stove': 0.5, 'child': 0.5, 'cows': 0.5, 'cattle': 0.5, 'pizza': 0.5, 'eating': 0.5, 'hydrant': 0.3333333333333333, 'middle': 0.5, 'grassy': 0.5, 'police': 0.5, 'officer': 0.5, 'uniform': 0.5, 'desk': 0.5, 'laptop,': 0.5, 'monitor,': 0.5, 'zebras': 0.5, 'tall': 0.5, 'ze': 0.5, 'cement': 0.5, 'row': 0.3333333333333333, 'motorcycles': 0.3333333333333333, 'rack': 0.5, 'them': 0.5, 'white': 0.3333333333333333, 'her': 0.5, 'hand': 0.5, 'filled': 0.25, 'lots': 0.5, 'fruit': 0.3333333333333333, 'cage': 0.5, 'camera': 0.5, 'parking': 0.3333333333333333, 'meter': 0.3333333333333333, 'stripe': 0.5, 'tracks': 0.5, 'station': 0.5, 'market': 0.5, 'men': 0.3333333333333333, 'plane': 0.3333333333333333, 'cloud': 0.5, 'runway': 0.5, 'blue': 0.5, 'couch,': 0.5, 'place': 0.5, 'petting': 0.5, 'traffic': 0.5, 'couple': 0.5, 'bench': 0.5, 'background': 0.5}\n"
     ]
    }
   ],
   "source": [
    "encoding_dict = Counter() # Counter is a subclass of dictionary for counting hashable objects\n",
    "threshold = 0 # threshold for word frequency # TODO: find a good threshold\n",
    "\n",
    "update_encoding_dict(generated_captions, encoding_dict)\n",
    "\n",
    "print (encoding_dict)\n",
    "\n",
    "# Optionally, create a more compressed form based on frequency\n",
    "compressed_dict = {word: idx for idx, (word, freq) in enumerate(encoding_dict.items()) if freq > threshold}\n",
    "\n",
    "# Create the dictionary of entropy values from encoding_dict\n",
    "entropy_dict = {word: -np.log(encoding_dict[word] / sum(encoding_dict.values())) \n",
    "                for word in encoding_dict}\n",
    "\n",
    "print (entropy_dict)\n",
    "# print 1/elem for elem in encoding_dict.values()\n",
    "reciprocal_dict = {word: 1/(encoding_dict[word]+1) for word in encoding_dict}\n",
    "print (reciprocal_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, captions):\n",
    "        self.encodings = encodings\n",
    "        self.captions = captions\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.captions[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `dataset` is your dataset containing images and captions\n",
    "images = [data['image'] for data in dataset_finetune]\n",
    "caption_ids = generated_predicted_ids_finetune\n",
    "\n",
    "# Process images and captions\n",
    "inputs = feature_extractor(images=images, return_tensors=\"pt\") \n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = CaptionDataset(inputs, caption_ids)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, original_weight, rank):\n",
    "        super(LoRALayer, self).__init__()\n",
    "        self.original_weight = original_weight\n",
    "        self.rank = rank\n",
    "        self.device = original_weight.device\n",
    "        self.U = nn.Parameter(torch.Tensor(self.original_weight.size(0), self.rank)).to(self.device)\n",
    "        self.V = nn.Parameter(torch.Tensor(self.rank, self.original_weight.size(1))).to(self.device)\n",
    "        nn.init.xavier_uniform_(self.U)\n",
    "        nn.init.xavier_uniform_(self.V)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.original_weight + self.U @ self.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the first attention layer of the encoder\n",
    "# TODO: Try modifying other layers as well and check the results\n",
    "lora_layers = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    original_weight = model.encoder.encoder.layer[0].attention.output.dense.weight\n",
    "    lora_layer = LoRALayer(original_weight, rank=10).to(device).forward()  # Choose an appropriate rank\n",
    "    # assign the new layer to the model\n",
    "    model.encoder.encoder.layer[0].attention.output.dense.weight.copy_(lora_layer)\n",
    "    # add the layer of the model to the list of LoRA layers\n",
    "    lora_layers.append(model.encoder.encoder.layer[0].attention.output.dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_lora_param(param, lora_layer):\n",
    "    # check if the parameter is part of the LoRA layer\n",
    "    print (lora_layer.parameters())\n",
    "    print (\"nuj\")\n",
    "    print (param)\n",
    "    return param in lora_layer.parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add two extra dimensions to generated_logits\n",
    "generated_probs_dict = F.softmax(mean_logits_dict, dim=-1)\n",
    "generated_probs_dict_expanded = generated_probs_dict.unsqueeze(0).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy_elbo_difference (prob_differences, unique_token_counts, D):\n",
    "    sigma = 0.01\n",
    "    # reduce prob_differences to 4D from 5D by taking norm square along the last dimension\n",
    "    prob_differences = prob_differences.to(device)\n",
    "    prob_differences = torch.norm(prob_differences, dim=-1)\n",
    "    print (prob_differences.shape)\n",
    "    # do elementwise for prob_differences: suqare\n",
    "    prob_differences = prob_differences**2\n",
    "    # multiply i,j,k th element of prob_differences with k th element of unique_token_probs\n",
    "    prob_differences = prob_differences * unique_token_counts\n",
    "    # take sum of all elements of prob_differences, hence scalar, then divide by 2*sigma^2*D\n",
    "    return torch.sum(prob_differences) / (2*sigma**2*D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy_elbo_cross_entropy (prob_differences, D):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy (prob_differences, D):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(outputs, batch, encoding_dict, lora_layers, lambda_val=0.05, lora_lambda_val = 0.01):\n",
    "    # Sending all to GPU\n",
    "    outputs.logits = outputs.logits.to(device)\n",
    "    outputs.loss = outputs.loss.to(device)\n",
    "    \n",
    "    # Standard captioning loss\n",
    "    standard_loss = outputs.loss\n",
    "\n",
    "    # Additional compression loss\n",
    "    compression_loss = 0\n",
    "    # add two dimensions to output probs at 2 and 3\n",
    "    outputs_probs = F.softmax(outputs.logits, dim=-1)\n",
    "    outputs_probs_expanded = outputs_probs.squeeze(1).unsqueeze(2).to(device)\n",
    "    # print shapes of generated_probs_expanded and outputs_probs_expanded\n",
    "    print (\"generated_probs_expanded.shape = \", generated_probs_dict_expanded.shape, outputs_probs_expanded.shape)\n",
    "    prob_differences = generated_probs_dict_expanded - outputs_probs_expanded\n",
    "    print (\"prob_differences.shape = \", outputs_probs.shape, generated_probs_dict_expanded.shape, outputs_probs_expanded.shape, prob_differences.shape)\n",
    "    # calculate the compression loss\n",
    "    # find number of elements in generated_predicted_logits\n",
    "    D = generated_probs_dict.numel()\n",
    "    compression_loss = lambda_val* calculate_entropy_elbo_difference (prob_differences, unique_token_counts_dict, D)\n",
    "    \n",
    "\n",
    "    # Optionally, add a term for LoRA regularization if needed\n",
    "    lora_regularization = 0\n",
    "    # for param in model.parameters():\n",
    "    #     for lora_layer in lora_layers:\n",
    "    #         if is_lora_param(param, lora_layer):\n",
    "    #             lora_regularization += torch.norm(param)\n",
    "    print (standard_loss, compression_loss)\n",
    "\n",
    "    return standard_loss + compression_loss + lora_lambda_val * lora_regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sagnik/Library/Python/3.9/lib/python/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]/var/folders/wd/7s_rgclx5rlc79rrjnspznh00000gn/T/ipykernel_62266/3431795457.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/wd/7s_rgclx5rlc79rrjnspznh00000gn/T/ipykernel_62266/3431795457.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.captions[idx])\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_probs_expanded.shape =  torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257])\n",
      "prob_differences.shape =  torch.Size([16, 15, 50257]) torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257]) torch.Size([16, 15, 287, 50257])\n",
      "torch.Size([16, 15, 287])\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>) tensor(5.8234, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  14%|█▍        | 1/7 [03:08<18:50, 188.48s/it, loss=6.75]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_probs_expanded.shape =  torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257])\n",
      "prob_differences.shape =  torch.Size([16, 15, 50257]) torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257]) torch.Size([16, 15, 287, 50257])\n",
      "torch.Size([16, 15, 287])\n",
      "tensor(1.2973, grad_fn=<NllLossBackward0>) tensor(5.1359, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  29%|██▊       | 2/7 [06:12<15:30, 186.08s/it, loss=6.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_probs_expanded.shape =  torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257])\n",
      "prob_differences.shape =  torch.Size([16, 15, 50257]) torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257]) torch.Size([16, 15, 287, 50257])\n",
      "torch.Size([16, 15, 287])\n",
      "tensor(1.3930, grad_fn=<NllLossBackward0>) tensor(4.9709, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  43%|████▎     | 3/7 [08:56<11:43, 175.80s/it, loss=6.36]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_probs_expanded.shape =  torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257])\n",
      "prob_differences.shape =  torch.Size([16, 15, 50257]) torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257]) torch.Size([16, 15, 287, 50257])\n",
      "torch.Size([16, 15, 287])\n",
      "tensor(1.5346, grad_fn=<NllLossBackward0>) tensor(4.7530, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  57%|█████▋    | 4/7 [11:47<08:42, 174.05s/it, loss=6.29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_probs_expanded.shape =  torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257])\n",
      "prob_differences.shape =  torch.Size([16, 15, 50257]) torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257]) torch.Size([16, 15, 287, 50257])\n",
      "torch.Size([16, 15, 287])\n",
      "tensor(1.5586, grad_fn=<NllLossBackward0>) tensor(4.7234, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  71%|███████▏  | 5/7 [14:35<05:43, 171.76s/it, loss=6.28]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_probs_expanded.shape =  torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257])\n",
      "prob_differences.shape =  torch.Size([16, 15, 50257]) torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257]) torch.Size([16, 15, 287, 50257])\n",
      "torch.Size([16, 15, 287])\n",
      "tensor(1.7431, grad_fn=<NllLossBackward0>) tensor(4.4591, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  86%|████████▌ | 6/7 [17:39<02:55, 175.85s/it, loss=6.2] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_probs_expanded.shape =  torch.Size([1, 1, 287, 50257]) torch.Size([4, 15, 1, 50257])\n",
      "prob_differences.shape =  torch.Size([4, 15, 50257]) torch.Size([1, 1, 287, 50257]) torch.Size([4, 15, 1, 50257]) torch.Size([4, 15, 287, 50257])\n",
      "torch.Size([4, 15, 287])\n",
      "tensor(1.8746, grad_fn=<NllLossBackward0>) tensor(1.0626, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 7/7 [17:47<00:00, 152.50s/it, loss=2.94]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_probs_expanded.shape =  torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257])\n",
      "prob_differences.shape =  torch.Size([16, 15, 50257]) torch.Size([1, 1, 287, 50257]) torch.Size([16, 15, 1, 50257]) torch.Size([16, 15, 287, 50257])\n",
      "torch.Size([16, 15, 287])\n",
      "tensor(1.8659, grad_fn=<NllLossBackward0>) tensor(4.2316, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Fine tuning using custom loss\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "lr = 1e-4\n",
    "num_epochs = 2\n",
    "\n",
    "optimizer = AdamW([param for param in model.parameters() if param.requires_grad], lr=lr)\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        with autocast():\n",
    "            # Forward pass\n",
    "            outputs = model(**batch)\n",
    "            loss = custom_loss(outputs, batch, encoding_dict, lora_layers)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory to save the model if it doesn't exist\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "# save model checkpoint to models directory using current timestamp and date\n",
    "torch.save(model.state_dict(), f\"models/{time.strftime('%Y%m%d-%H%M%S')}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderModel(\n",
       "  (encoder): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (pooler): ViTPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load latest model checkpoint among all the saved models\n",
    "latest_model = torch.load(max(glob.glob('models/*.pth'), key=os.path.getctime))\n",
    "# load the model with the latest checkpoint\n",
    "model.load_state_dict(latest_model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n",
      "EOS has been generated\n"
     ]
    }
   ],
   "source": [
    "# Generate captions for the test dataset\n",
    "generated_captions_custom_model = []\n",
    "# Iterate over the dataset and generate captions\n",
    "for data in dataset_finetune:\n",
    "    image = data['image']\n",
    "    generated_logits, generated_predicted_ids, caption = generate_caption_with_logits(image)\n",
    "    generated_captions_custom_model.append(caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode compressed dictionary word using manual huffman encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace compressed_dict words occurring in the generated_captions_custom_model with their corresponding huffman encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare encoded generated_captions_custom_model + huffman encoding dictionary information with the original generated_captions to calculate compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a green truck parked next to a curb a green truck parked next WAIT a man is sitting on a man sitting on a man sitting on a man\n",
      "a man is walking down the street with a skateboard a man WAIT a man is playing a man playing a man playing a man playing a man\n",
      "a baseball player swinging a bat at a ball a baseball player swinging WAIT a man is playing a man playing a man playing a man playing a man\n",
      "a cow is standing in a field of grass a cow is standing WAIT a man is playing a man playing a man playing a man playing a man\n",
      "a black dog sitting in the back of a truck a black dog WAIT a man is sitting on a man sitting on a man sitting on a man\n",
      "a man wearing a bow tie and glasses a man wearing a bow WAIT a man is a man is a man is a man is a man is\n",
      "a dining room table with a large bowl of food a large kitchen WAIT a man is sitting on a man sitting on a man sitting on a man\n",
      "a man standing next to a wall with a bunch of guitars a WAIT a man is a man is a man is a man is a man is\n",
      "a man is playing tennis on a clay court a man is playing WAIT a man is playing tennis court court court a man playing a man\n",
      "a man and a woman playing a game of frisbee a WAIT a man is playing tennis court court a man playing a man playing\n",
      "a woman and a man are drinking wine people are sitting at a WAIT a man is a man is a man is a man is a man is\n",
      "people are standing around a table people are drinking wine people WAIT a man is a man is a man is a man is a man is\n",
      "a zebra standing in a fenced in area a zebra WAIT a man is a man is a man is a man is a man is\n",
      "two dogs are looking at each other in a room a dog is WAIT a man is playing a man playing a man playing a man playing a man\n",
      "a horse grazing in a field with a tree a horse grazing in WAIT a man is playing a man playing a man playing a man playing a man\n",
      "a bird perched on top of a bird feeder a bird sitting WAIT a man is playing a man playing a man playing a man playing a man\n",
      "a train on a track near a fence a train on a track WAIT a man is a man is a man is a man is a man is\n",
      "a plate of food with a fish and vegetables a person sitting at WAIT a man is sitting on a man sitting on a man sitting on a man\n",
      "an elephant with a large trunk standing on a dirt ground a elephant WAIT a man is a man is a man is a man is a man is\n",
      "people are watching a television show people are watching a movie  WAIT a man is a man is a man is a man is a man is\n",
      "a woman is cooking food in a kitchen a woman is cooking food WAIT a man is a man is a man is a man is a man is\n",
      "a stuffed animal with a teddy bear on it a teddy WAIT a man is a man is a man is a man is a man is\n",
      "a plate of food with meat, broccoli and potatoes a plate of WAIT a man is a man is a man is a man is a man is\n",
      "a man in a suit and tie looking at his cell phone a WAIT a man sitting on a chair chair chair chair chair chair chair chair chair chair\n",
      "a man holding a tennis racquet on a tennis court a man WAIT a man is playing tennis court a man playing a man playing tennis\n",
      "a man sitting on a couch with a laptop a man sitting on WAIT a man is a man is a man is a man is a man is\n",
      "a motorcycle parked on the side of a road a motorcycle is parked WAIT a man is sitting on a man sitting on a man sitting on a man\n",
      "a bear walking through a forest with leaves a black bear standing in WAIT a man is a man is a man is a man is a man is\n",
      "a truck with a bed and a fence a truck with a bed WAIT a man is sitting on a man sitting on a man sitting on a man\n",
      "a plate of food on a table a hot dog on a bun WAIT a man is a man is a man is a man is a man is\n",
      "a man wearing a hat and a red scarf a man with a WAIT a man is a man is a man is a man is a man is\n",
      "a herd of sheep grazing in a field a herd of sheep standing WAIT a man is a man is a man is a man is a man is\n",
      "a remote control sitting on top of a couch a remote control sitting WAIT a man is sitting on a man sitting on a man sitting on a man\n",
      "a large jetliner flying through a cloudy sky a large jetliner WAIT a man is playing a man playing tennis court a man playing a\n",
      "a man in a suit and tie speaking to a crowd a man WAIT a man is a man is a man is a man is a man is\n",
      "a plate of food with meat, rice and vegetables a plate of WAIT a man is a man is a man is a man is a man is\n",
      "a person jumping a skateboard on a ledge a person jumping a WAIT a man sitting on a chair chair chair chair chair chair chair chair chair chair\n",
      "a man is playing tennis on a court a man is playing tennis WAIT a man is playing tennis court court a man playing a man playing\n",
      "a giraffe standing next to a tree with a leaf on it's head WAIT a man is walking on a man is a man is a man is a\n",
      "a woman standing on a beach holding an umbrella people are walking on WAIT a man is playing a man playing a man playing a man playing a man\n",
      "a man riding a wave on top of a surfboard a sur WAIT a man is playing a man playing tennis court a man playing a\n",
      "a teddy bear sitting on a chair in a room a t WAIT a man is a man is a man is a man is a man is\n",
      "a man riding a bike down a street a man riding a motorcycle WAIT a man is a man is a man is a man is a man is\n",
      "a bedroom with a bed, chair, and a window a room WAIT a man is sitting on a man sitting on a man sitting on a man\n",
      "a clock tower with a clock on it's side a clock tower WAIT a man is a man is a man is a man is a man is\n",
      "a fire truck is parked at a stop light a fire truck is WAIT a man is sitting on a man sitting on a man sitting on a man\n",
      "a collection of items including a purse, a bag, a pair of shoes WAIT a man is a man is a man is a man is a man is\n",
      "a large brick building with a clock tower a large building with a WAIT a man is playing a man playing a man playing a man playing a man\n",
      "a woman is sitting on the sidewalk while a man walks by people WAIT a man is playing a man playing tennis court a man playing a\n",
      "a tray of food with a spoon and a bowl of food a WAIT a man is a man is a man is a man is a man is\n",
      "Counter({'a': 167, 'man': 24, 'on': 22, 'of': 21, 'with': 20, 'is': 14, 'in': 13, 'and': 12, 'standing': 10, 'sitting': 10, 'food': 9, 'are': 8, 'people': 8, 'truck': 7, 'large': 7, 'at': 6, 'woman': 6, 'plate': 6, 'parked': 5, 'playing': 5, 'tennis': 5, 'next': 4, 'to': 4, 'the': 4, 'dog': 4, 'room': 4, 'bear': 4, 'clock': 4, 'walking': 3, 'field': 3, 'black': 3, 'wearing': 3, 'tie': 3, 'table': 3, 'court': 3, 'grazing': 3, 'bird': 3, 'top': 3, 'person': 3, 'teddy': 3, 'motorcycle': 3, 'riding': 3, 'tower': 3, 'green': 2, 'down': 2, 'street': 2, 'skateboard': 2, 'baseball': 2, 'player': 2, 'swinging': 2, 'cow': 2, 'bow': 2, 'bowl': 2, 'kitchen': 2, 'drinking': 2, 'wine': 2, 'zebra': 2, 'looking': 2, 'horse': 2, 'tree': 2, 'train': 2, 'track': 2, 'fence': 2, 'vegetables': 2, 'an': 2, 'elephant': 2, 'watching': 2, 'cooking': 2, 'meat,': 2, 'suit': 2, 'holding': 2, 'couch': 2, 'side': 2, 'through': 2, 'bed': 2, 'herd': 2, 'sheep': 2, 'remote': 2, 'control': 2, 'jetliner': 2, 'jumping': 2, \"it's\": 2, 'fire': 2, 'building': 2, 'curb': 1, 'bat': 1, 'ball': 1, 'grass': 1, 'back': 1, 'glasses': 1, 'dining': 1, 'wall': 1, 'bunch': 1, 'guitars': 1, 'clay': 1, 'game': 1, 'frisbee': 1, 'around': 1, 'fenced': 1, 'area': 1, 'two': 1, 'dogs': 1, 'each': 1, 'other': 1, 'perched': 1, 'feeder': 1, 'near': 1, 'fish': 1, 'trunk': 1, 'dirt': 1, 'ground': 1, 'television': 1, 'show': 1, 'movie': 1, 'stuffed': 1, 'animal': 1, 'it': 1, 'broccoli': 1, 'potatoes': 1, 'his': 1, 'cell': 1, 'phone': 1, 'racquet': 1, 'laptop': 1, 'road': 1, 'forest': 1, 'leaves': 1, 'hot': 1, 'bun': 1, 'hat': 1, 'red': 1, 'scarf': 1, 'flying': 1, 'cloudy': 1, 'sky': 1, 'speaking': 1, 'crowd': 1, 'rice': 1, 'ledge': 1, 'giraffe': 1, 'leaf': 1, 'head': 1, 'beach': 1, 'umbrella': 1, 'wave': 1, 'surfboard': 1, 'sur': 1, 'chair': 1, 't': 1, 'bike': 1, 'bedroom': 1, 'bed,': 1, 'chair,': 1, 'window': 1, 'stop': 1, 'light': 1, 'collection': 1, 'items': 1, 'including': 1, 'purse,': 1, 'bag,': 1, 'pair': 1, 'shoes': 1, 'brick': 1, 'sidewalk': 1, 'while': 1, 'walks': 1, 'by': 1, 'tray': 1, 'spoon': 1})\n"
     ]
    }
   ],
   "source": [
    "# print generated_captions and generated_captions_custom_model elementwise to compare the results\n",
    "for i in range(len(generated_captions_finetune)):\n",
    "    print (generated_captions_finetune[i], \"WAIT\", generated_captions_custom_model[i])\n",
    "# print the frequency of each word in generated_captions\n",
    "print (encoding_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
